{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "009c0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\User\\\\Desktop\\\\url_dataset_updated.csv')\n",
    "\n",
    "# Drop all duplicates from df\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Reset the index after dropping duplicates\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "url_column_name = 'URL'  # Replace with your actual column name\n",
    "\n",
    "# Function to concatenate \"https://\" to URLs labeled with 0\n",
    "def add_https(url, label):\n",
    "    if label == 0:\n",
    "        return \"https://\" + url\n",
    "    else:\n",
    "        return url\n",
    "\n",
    "# Apply the function to the URL column\n",
    "df[url_column_name] = df.apply(lambda row: add_https(row[url_column_name], row['Label']), axis=1)\n",
    "\n",
    "\n",
    "# Separate the dataset into malicious and benign\n",
    "malicious_df = df[df['Label'] == 1]\n",
    "benign_df = df[df['Label'] == 0]\n",
    "\n",
    "# Randomly sample 150,000 entries from each\n",
    "malicious_sampled_df = resample(malicious_df, n_samples=150000, random_state=42)\n",
    "benign_sampled_df = resample(benign_df, n_samples=150000, random_state=42)\n",
    "\n",
    "# Combine the sampled data\n",
    "balanced_df = pd.concat([malicious_sampled_df, benign_sampled_df])\n",
    "\n",
    "# Shuffle the combined dataset to mix malicious and benign URLs\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# Now, balanced_df contains the balanced dataset ready for further processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a02635b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://etransfers.interac.ca-ssl.net/sh/2o05I9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://betterhealthsmoothies.com/Adobe/adobe-3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://lloydsbank.deregister-payee-secure-auth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://archive.md</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pkg00-atx.netgate.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>https://infomation-fb-service.e82443.repl.co</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>https://img-1000736.ad-score.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>http://sosyalsat.com/help/home.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>https://storageapi.fleek.co/12678f8a-04f9-4b69...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>https://trepievirealestate.com/paintdesk/auth/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL  Label\n",
       "0       http://etransfers.interac.ca-ssl.net/sh/2o05I9...      1\n",
       "1       http://betterhealthsmoothies.com/Adobe/adobe-3...      1\n",
       "2       http://lloydsbank.deregister-payee-secure-auth...      1\n",
       "3                                      https://archive.md      0\n",
       "4                           https://pkg00-atx.netgate.com      0\n",
       "...                                                   ...    ...\n",
       "299995       https://infomation-fb-service.e82443.repl.co      1\n",
       "299996                   https://img-1000736.ad-score.com      0\n",
       "299997                http://sosyalsat.com/help/home.html      1\n",
       "299998  https://storageapi.fleek.co/12678f8a-04f9-4b69...      1\n",
       "299999  https://trepievirealestate.com/paintdesk/auth/...      1\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "71c5b570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betterhealthsmoothies.com/Adobe/adobe-3D6/inde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lloydsbank.deregister-payee-secure-auth.com/Lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archive.md</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkg00-atx.netgate.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>infomation-fb-service.e82443.repl.co</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>img-1000736.ad-score.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>sosyalsat.com/help/home.html</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>storageapi.fleek.co/12678f8a-04f9-4b69-a70f-49...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>trepievirealestate.com/paintdesk/auth/1/inner_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL  Label\n",
       "0       etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/...      1\n",
       "1       betterhealthsmoothies.com/Adobe/adobe-3D6/inde...      1\n",
       "2       lloydsbank.deregister-payee-secure-auth.com/Lo...      1\n",
       "3                                              archive.md      0\n",
       "4                                   pkg00-atx.netgate.com      0\n",
       "...                                                   ...    ...\n",
       "299995               infomation-fb-service.e82443.repl.co      1\n",
       "299996                           img-1000736.ad-score.com      0\n",
       "299997                       sosyalsat.com/help/home.html      1\n",
       "299998  storageapi.fleek.co/12678f8a-04f9-4b69-a70f-49...      1\n",
       "299999  trepievirealestate.com/paintdesk/auth/1/inner_...      1\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1903987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9494833333333333\n",
      "Confusion Matrix:\n",
      " [[29158   904]\n",
      " [ 2127 27811]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95     30062\n",
      "           1       0.97      0.93      0.95     29938\n",
      "\n",
      "    accuracy                           0.95     60000\n",
      "   macro avg       0.95      0.95      0.95     60000\n",
      "weighted avg       0.95      0.95      0.95     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import tldextract \n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "import whois\n",
    "from datetime import datetime\n",
    "\n",
    "def ensure_scheme(url):\n",
    "    if not urlparse(url).scheme:\n",
    "        url = 'http://' + url\n",
    "    return url\n",
    "\n",
    "# Feature extraction functions\n",
    "def get_url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def get_dot_count(url):\n",
    "    return url.count('.')\n",
    "\n",
    "def contains_security_sensitive_words(url):\n",
    "    security_sensitive_words = [\n",
    "    'login', 'password', 'admin', 'root', 'secret', 'private', 'secure', 'confidential', \n",
    "    'bank', 'creditcard', 'account', 'authentication', 'authorization', 'session', 'token', \n",
    "    'apikey', 'ssl', 'https', 'secure', 'encrypted', 'auth', 'signin', 'signup', 'verification', \n",
    "    'resetpassword', 'change-password', 'forgot-password', 'otp', '2fa', 'phishing', 'malware', \n",
    "    'virus', 'trojan', 'exploit', 'hacker', 'attack', 'security', 'vulnerable', 'injection', \n",
    "    'xss', 'csrf', 'dos', 'ddos', 'bruteforce', 'firewall', 'vpn', 'proxy', 'tor', 'security-question', \n",
    "    'privacy-policy'\n",
    "]\n",
    "\n",
    "    return int(any(word in url for word in security_sensitive_words))\n",
    "\n",
    "def get_directory_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    return len(path)\n",
    "\n",
    "def get_sub_directory_count(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    return path.count('/') - 1\n",
    "\n",
    "def get_token_count_in_path(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = path.split('/')\n",
    "    return len(tokens) - 1\n",
    "\n",
    "def get_largest_token_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = path.split('/')\n",
    "    if tokens:\n",
    "        return max(len(token) for token in tokens)\n",
    "    return 0\n",
    "\n",
    "def get_average_token_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = [token for token in path.split('/') if token]\n",
    "    if tokens:\n",
    "        return np.mean([len(token) for token in tokens])\n",
    "    return 0\n",
    "\n",
    "def get_file_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    return len(filename)\n",
    "\n",
    "def get_dot_count_in_file(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    return filename.count('.')\n",
    "\n",
    "def get_delimiter_count_in_file(url):\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    delimiters = ['.', '_', '-']\n",
    "    return sum(filename.count(delimiter) for delimiter in delimiters)\n",
    "\n",
    "def get_arguments_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    return len(query)\n",
    "\n",
    "def get_number_of_arguments(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    return len(parse_qs(query))\n",
    "\n",
    "def get_length_of_largest_argument_value(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    params = parse_qs(query)\n",
    "    if params:\n",
    "        return max(len(max(values, key=len)) for values in params.values())\n",
    "    return 0\n",
    "\n",
    "def get_max_delimiters_in_arguments(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    params = parse_qs(query)\n",
    "    delimiters = ['&', '=', '-', '_']\n",
    "    if params:\n",
    "        return max(sum(value.count(delimiter) for delimiter in delimiters) for values in params.values() for value in values)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_hyphen_count_in_domain(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    return domain.count('-')\n",
    "\n",
    "def contains_ip(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    try:\n",
    "        socket.inet_aton(domain)\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_domain_features(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(ensure_scheme(url)).netloc\n",
    "    tokens = domain.split('.')\n",
    "    \n",
    "    # Domain Length\n",
    "    domain_length = len(domain)\n",
    "    \n",
    "    # Count of Tokens in the Domain\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # Length of Largest Token in the Domain\n",
    "    largest_token_length = max(len(token) for token in tokens) if tokens else 0\n",
    "    \n",
    "    # Average Domain Token Length\n",
    "    average_token_length = sum(len(token) for token in tokens) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return domain_length, token_count, largest_token_length, average_token_length\n",
    "\n",
    "# New feature extraction functions\n",
    "def get_special_character_count(url):\n",
    "    special_characters = ['@', '=', '+', '*', '?', '&', '%', '$', '#', '!']\n",
    "    return sum(url.count(char) for char in special_characters)\n",
    "\n",
    "def get_entropy(url):\n",
    "    # Count the frequency of each character in the string\n",
    "    freq = Counter(url)\n",
    "    # Calculate the probabilities\n",
    "    probs = [count / len(url) for count in freq.values()]\n",
    "    # Calculate the Shannon entropy\n",
    "    entropy = -sum(p * math.log(p, 2) for p in probs if p > 0)\n",
    "    return entropy\n",
    "\n",
    "def check_url_shortened(url):\n",
    "    shortened_services = ['bit.ly', 'tinyurl.com', 'goo.gl', 'ow.ly', 't.co']\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    return int(domain in shortened_services)\n",
    "\n",
    "def get_subdomain_count(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain_parts = urlparse(url).netloc.split('.')\n",
    "    # Count as subdomains any parts beyond the second-level domain and TLD\n",
    "    return max(0, len(domain_parts) - 2)\n",
    "\n",
    "def get_suspicious_tld(url):\n",
    "    suspicious_tlds = ['xyz', 'top', 'loan', 'win', 'club']\n",
    "    url = ensure_scheme(url)\n",
    "    tld = urlparse(url).netloc.split('.')[-1]\n",
    "    return int(tld in suspicious_tlds)\n",
    "\n",
    "def get_numeric_ratio(url):\n",
    "    numeric_chars = sum(c.isdigit() for c in url)\n",
    "    return numeric_chars / len(url) if len(url) > 0 else 0\n",
    "\n",
    "def get_word_count(url):\n",
    "    words = re.findall(r'\\w+', url)\n",
    "    return len(words)\n",
    "    \n",
    "\n",
    "# Apply feature extraction\n",
    "features = balanced_df['URL'].apply(lambda x: pd.Series({\n",
    "    'url_length': get_url_length(x),\n",
    "    'dot_count': get_dot_count(x),\n",
    "    'hyphen_count_domain': get_hyphen_count_in_domain(x),\n",
    "    'security_sensitive_words': contains_security_sensitive_words(x),\n",
    "    'directory_length': get_directory_length(x),\n",
    "    'sub_directory_count': get_sub_directory_count(x),\n",
    "    'token_count_path': get_token_count_in_path(x),\n",
    "    'largest_token_length': get_largest_token_length(x),\n",
    "    'average_token_length': get_average_token_length(x),\n",
    "    'file_length': get_file_length(x),\n",
    "    'contains_ip': contains_ip(x),\n",
    "    'dot_count_in_file': get_dot_count_in_file(x),\n",
    "    'delimiter_count_in_file': get_delimiter_count_in_file(x),\n",
    "    'arguments_length': get_arguments_length(x),\n",
    "    'number_of_arguments': get_number_of_arguments(x),\n",
    "    'length_of_largest_argument_value': get_length_of_largest_argument_value(x),\n",
    "    'max_delimiters_in_arguments': get_max_delimiters_in_arguments(x),\n",
    "    'special_character_count': get_special_character_count(x),\n",
    "    'entropy': get_entropy(x),\n",
    "    'url_shortened': check_url_shortened(x),\n",
    "    'subdomain_count': get_subdomain_count(x),\n",
    "    'suspicious_tld': get_suspicious_tld(x),\n",
    "    'numeric_ratio': get_numeric_ratio(x),\n",
    "    'domain_length': get_domain_features(x)[0],\n",
    "    'domain_token_count': get_domain_features(x)[1],\n",
    "    'largest_domain_token_length': get_domain_features(x)[2],\n",
    "    'average_domain_token_length': get_domain_features(x)[3],\n",
    "    'word_count': get_word_count(x)\n",
    "}))\n",
    "\n",
    "\n",
    "# Concatenate original DF with features\n",
    "balanced_df = pd.concat([balanced_df, features], axis=1)\n",
    "\n",
    "\n",
    "# Define X and y correctly\n",
    "X = balanced_df.drop(['Label', 'URL'], axis=1)  # Features\n",
    "y = balanced_df['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "# Since your features are already numerical, directly use RandomForestClassifier without TfidfVectorizer\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d20ee435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Label</th>\n",
       "      <th>url_length</th>\n",
       "      <th>dot_count</th>\n",
       "      <th>hyphen_count_domain</th>\n",
       "      <th>security_sensitive_words</th>\n",
       "      <th>directory_length</th>\n",
       "      <th>sub_directory_count</th>\n",
       "      <th>token_count_path</th>\n",
       "      <th>largest_token_length</th>\n",
       "      <th>...</th>\n",
       "      <th>port_number</th>\n",
       "      <th>subdomain_count</th>\n",
       "      <th>suspicious_tld</th>\n",
       "      <th>numeric_ratio</th>\n",
       "      <th>url_is_internationalized</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>largest_domain_token_length</th>\n",
       "      <th>average_domain_token_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/...</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betterhealthsmoothies.com/Adobe/adobe-3D6/inde...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lloydsbank.deregister-payee-secure-auth.com/Lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>archive.md</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pkg00-atx.netgate.com</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>infomation-fb-service.e82443.repl.co</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>img-1000736.ad-score.com</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>sosyalsat.com/help/home.html</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>storageapi.fleek.co/12678f8a-04f9-4b69-a70f-49...</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>trepievirealestate.com/paintdesk/auth/1/inner_...</td>\n",
       "      <td>1</td>\n",
       "      <td>286.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      URL  Label  url_length  \\\n",
       "0       etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/...      1        58.0   \n",
       "1       betterhealthsmoothies.com/Adobe/adobe-3D6/inde...      1        51.0   \n",
       "2       lloydsbank.deregister-payee-secure-auth.com/Lo...      1        53.0   \n",
       "3                                              archive.md      0        10.0   \n",
       "4                                   pkg00-atx.netgate.com      0        21.0   \n",
       "...                                                   ...    ...         ...   \n",
       "299995               infomation-fb-service.e82443.repl.co      1        36.0   \n",
       "299996                           img-1000736.ad-score.com      0        24.0   \n",
       "299997                       sosyalsat.com/help/home.html      1        28.0   \n",
       "299998  storageapi.fleek.co/12678f8a-04f9-4b69-a70f-49...      1        75.0   \n",
       "299999  trepievirealestate.com/paintdesk/auth/1/inner_...      1       286.0   \n",
       "\n",
       "        dot_count  hyphen_count_domain  security_sensitive_words  \\\n",
       "0             4.0                  1.0                       0.0   \n",
       "1             2.0                  0.0                       0.0   \n",
       "2             3.0                  3.0                       1.0   \n",
       "3             1.0                  0.0                       0.0   \n",
       "4             2.0                  1.0                       0.0   \n",
       "...           ...                  ...                       ...   \n",
       "299995        3.0                  2.0                       0.0   \n",
       "299996        2.0                  2.0                       0.0   \n",
       "299997        2.0                  0.0                       0.0   \n",
       "299998        3.0                  0.0                       0.0   \n",
       "299999        2.0                  0.0                       0.0   \n",
       "\n",
       "        directory_length  sub_directory_count  token_count_path  \\\n",
       "0                   29.0                  3.0               4.0   \n",
       "1                   26.0                  2.0               3.0   \n",
       "2                   10.0                  0.0               1.0   \n",
       "3                    0.0                 -1.0               0.0   \n",
       "4                    0.0                 -1.0               0.0   \n",
       "...                  ...                  ...               ...   \n",
       "299995               0.0                 -1.0               0.0   \n",
       "299996               0.0                 -1.0               0.0   \n",
       "299997              15.0                  1.0               2.0   \n",
       "299998              56.0                  1.0               2.0   \n",
       "299999              33.0                  3.0               4.0   \n",
       "\n",
       "        largest_token_length  ...  port_number  subdomain_count  \\\n",
       "0                       12.0  ...         -1.0              2.0   \n",
       "1                        9.0  ...         -1.0              0.0   \n",
       "2                        9.0  ...         -1.0              1.0   \n",
       "3                        0.0  ...         -1.0              0.0   \n",
       "4                        0.0  ...         -1.0              1.0   \n",
       "...                      ...  ...          ...              ...   \n",
       "299995                   0.0  ...         -1.0              2.0   \n",
       "299996                   0.0  ...         -1.0              1.0   \n",
       "299997                   9.0  ...         -1.0              0.0   \n",
       "299998                  43.0  ...         -1.0              1.0   \n",
       "299999                  15.0  ...         -1.0              0.0   \n",
       "\n",
       "        suspicious_tld  numeric_ratio  url_is_internationalized  \\\n",
       "0                  0.0       0.068966                       0.0   \n",
       "1                  0.0       0.039216                       0.0   \n",
       "2                  0.0       0.000000                       0.0   \n",
       "3                  0.0       0.000000                       0.0   \n",
       "4                  0.0       0.095238                       0.0   \n",
       "...                ...            ...                       ...   \n",
       "299995             0.0       0.138889                       0.0   \n",
       "299996             0.0       0.291667                       0.0   \n",
       "299997             0.0       0.000000                       0.0   \n",
       "299998             0.0       0.320000                       0.0   \n",
       "299999             0.0       0.493007                       0.0   \n",
       "\n",
       "        domain_length  domain_token_count  largest_domain_token_length  \\\n",
       "0                29.0                 4.0                         10.0   \n",
       "1                25.0                 2.0                         21.0   \n",
       "2                43.0                 3.0                         28.0   \n",
       "3                10.0                 2.0                          7.0   \n",
       "4                21.0                 3.0                          9.0   \n",
       "...               ...                 ...                          ...   \n",
       "299995           36.0                 4.0                         21.0   \n",
       "299996           24.0                 3.0                         11.0   \n",
       "299997           13.0                 2.0                          9.0   \n",
       "299998           19.0                 3.0                         10.0   \n",
       "299999           22.0                 2.0                         18.0   \n",
       "\n",
       "        average_domain_token_length  word_count  \n",
       "0                          6.500000        10.0  \n",
       "1                         12.000000         7.0  \n",
       "2                         13.666667         8.0  \n",
       "3                          4.500000         2.0  \n",
       "4                          6.333333         4.0  \n",
       "...                             ...         ...  \n",
       "299995                     8.250000         6.0  \n",
       "299996                     7.333333         5.0  \n",
       "299997                     6.000000         5.0  \n",
       "299998                     5.666667        11.0  \n",
       "299999                    10.500000        14.0  \n",
       "\n",
       "[300000 rows x 32 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d995cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with \"entropy\" larger than 0: 55\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'balanced_df' contains your feature \"entropy\"\n",
    "num_rows_entropy_greater_than_zero = (balanced_df['port_number'] > 0).sum()\n",
    "\n",
    "print(f'Number of rows with \"entropy\" larger than 0: {num_rows_entropy_greater_than_zero}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0db0b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 162s 106ms/step - loss: 0.2499 - acc: 0.9051 - val_loss: 0.1960 - val_acc: 0.9235\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 158s 105ms/step - loss: 0.1877 - acc: 0.9290 - val_loss: 0.1700 - val_acc: 0.9320\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 157s 105ms/step - loss: 0.1630 - acc: 0.9385 - val_loss: 0.1625 - val_acc: 0.9383\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 161s 107ms/step - loss: 0.1488 - acc: 0.9443 - val_loss: 0.1441 - val_acc: 0.9444\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 159s 106ms/step - loss: 0.1397 - acc: 0.9478 - val_loss: 0.1331 - val_acc: 0.9492\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 161s 107ms/step - loss: 0.1344 - acc: 0.9504 - val_loss: 0.1287 - val_acc: 0.9506\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 161s 107ms/step - loss: 0.1275 - acc: 0.9526 - val_loss: 0.1267 - val_acc: 0.9519\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 160s 107ms/step - loss: 0.1228 - acc: 0.9547 - val_loss: 0.1205 - val_acc: 0.9535\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 161s 108ms/step - loss: 0.1179 - acc: 0.9564 - val_loss: 0.1157 - val_acc: 0.9564\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 161s 108ms/step - loss: 0.1135 - acc: 0.9579 - val_loss: 0.1194 - val_acc: 0.9546\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 178s 119ms/step - loss: 0.1103 - acc: 0.9590 - val_loss: 0.1129 - val_acc: 0.9579\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 181s 121ms/step - loss: 0.1061 - acc: 0.9608 - val_loss: 0.1078 - val_acc: 0.9595\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 181s 121ms/step - loss: 0.1016 - acc: 0.9626 - val_loss: 0.1094 - val_acc: 0.9598\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 179s 119ms/step - loss: 0.0982 - acc: 0.9641 - val_loss: 0.1083 - val_acc: 0.9601\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 182s 121ms/step - loss: 0.0953 - acc: 0.9650 - val_loss: 0.1066 - val_acc: 0.9603\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 180s 120ms/step - loss: 0.0916 - acc: 0.9664 - val_loss: 0.1027 - val_acc: 0.9622\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 179s 120ms/step - loss: 0.0888 - acc: 0.9672 - val_loss: 0.1022 - val_acc: 0.9629\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 179s 120ms/step - loss: 0.0861 - acc: 0.9688 - val_loss: 0.1010 - val_acc: 0.9633\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 180s 120ms/step - loss: 0.0840 - acc: 0.9695 - val_loss: 0.1016 - val_acc: 0.9642\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 179s 119ms/step - loss: 0.0808 - acc: 0.9706 - val_loss: 0.1008 - val_acc: 0.9634\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 181s 121ms/step - loss: 0.0787 - acc: 0.9716 - val_loss: 0.0973 - val_acc: 0.9650\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 179s 119ms/step - loss: 0.0761 - acc: 0.9725 - val_loss: 0.1054 - val_acc: 0.9642\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 180s 120ms/step - loss: 0.0740 - acc: 0.9734 - val_loss: 0.1022 - val_acc: 0.9649\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 168s 112ms/step - loss: 0.0709 - acc: 0.9743 - val_loss: 0.1027 - val_acc: 0.9651\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 165s 110ms/step - loss: 0.0700 - acc: 0.9749 - val_loss: 0.1050 - val_acc: 0.9646\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 169s 112ms/step - loss: 0.0682 - acc: 0.9752 - val_loss: 0.1057 - val_acc: 0.9642\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 167s 112ms/step - loss: 0.0659 - acc: 0.9762 - val_loss: 0.1031 - val_acc: 0.9654\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 170s 113ms/step - loss: 0.0644 - acc: 0.9768 - val_loss: 0.1018 - val_acc: 0.9657\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 166s 110ms/step - loss: 0.0629 - acc: 0.9773 - val_loss: 0.1077 - val_acc: 0.9645\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 166s 111ms/step - loss: 0.0616 - acc: 0.9779 - val_loss: 0.1051 - val_acc: 0.9660\n",
      "1875/1875 [==============================] - 25s 13ms/step\n",
      "Accuracy: 0.9651333333333333\n",
      "Confusion Matrix:\n",
      " [[29643   419]\n",
      " [ 1673 28265]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97     30062\n",
      "           1       0.99      0.94      0.96     29938\n",
      "\n",
      "    accuracy                           0.97     60000\n",
      "   macro avg       0.97      0.97      0.97     60000\n",
      "weighted avg       0.97      0.97      0.97     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Assuming balanced_df is your DataFrame with URLs and labels\n",
    "\n",
    "# Tokenization and sequence padding parameters\n",
    "max_len = 100  # Adjust based on the length of the longest URL in your dataset\n",
    "max_words = 60000  # Adjust based on the size of your vocabulary\n",
    "\n",
    "# Tokenize the URLs\n",
    "tokenizer = Tokenizer(num_words=max_words, char_level=True)\n",
    "tokenizer.fit_on_texts(balanced_df['URL'])\n",
    "sequences = tokenizer.texts_to_sequences(balanced_df['URL'])\n",
    "\n",
    "# Pad the sequences\n",
    "data = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Labels\n",
    "labels = np.asarray(balanced_df['Label'])\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Model definition\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))  # Add return_sequences if stacking LSTM layers\n",
    "model.add(Dropout(0.5))  # Adjust dropout rate as needed\n",
    "model.add(Bidirectional(LSTM(32)))  # Second LSTM layer, without return_sequences\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))  # Add L2 regularization\n",
    "model.add(Dropout(0.5))  # Adjust dropout rate as needed\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=128, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test_classes, y_pred_classes))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_classes, y_pred_classes))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fdf8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372ea62838a0478b816e5897cc1e9e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 51\u001b[0m\n\u001b[0;32m     47\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     48\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     49\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: batch[\u001b[38;5;241m1\u001b[39m]}\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     53\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1562\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1555\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1560\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1562\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert(\n\u001b[0;32m   1563\u001b[0m     input_ids,\n\u001b[0;32m   1564\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1565\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[0;32m   1566\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   1567\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1568\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m   1569\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1570\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1571\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1572\u001b[0m )\n\u001b[0;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1576\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m   1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1016\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   1017\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[1;32m-> 1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1023\u001b[0m     embedding_output,\n\u001b[0;32m   1024\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1025\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1026\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1027\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1028\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1029\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1030\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1031\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1032\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1033\u001b[0m )\n\u001b[0;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1035\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:612\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    603\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[0;32m    604\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m    605\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    609\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    610\u001b[0m     )\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 612\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    613\u001b[0m         hidden_states,\n\u001b[0;32m    614\u001b[0m         attention_mask,\n\u001b[0;32m    615\u001b[0m         layer_head_mask,\n\u001b[0;32m    616\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    617\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    618\u001b[0m         past_key_value,\n\u001b[0;32m    619\u001b[0m         output_attentions,\n\u001b[0;32m    620\u001b[0m     )\n\u001b[0;32m    622\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    536\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    537\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 539\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    541\u001b[0m )\n\u001b[0;32m    542\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 551\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m    552\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:451\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 451\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    452\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load dataset and preprocess as needed\n",
    "# balanced_df = ...\n",
    "\n",
    "# Tokenization and sequence padding parameters\n",
    "max_len = 200  # Adjust based on the length of the longest URL in your dataset\n",
    "\n",
    "# Tokenize the URLs using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "inputs = tokenizer(balanced_df['URL'].tolist(), padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n",
    "\n",
    "# Labels\n",
    "labels = torch.tensor(balanced_df['Label'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs['input_ids'], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create PyTorch DataLoader for training and testing data\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 3  # Adjust as needed\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[0],\n",
    "                  'labels': batch[1]}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[0]}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
    "        true_labels.extend(batch[1].tolist())\n",
    "\n",
    "# Convert predictions and true labels to numpy arrays\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(true_labels)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(true_labels, predictions))\n",
    "print(\"Classification Report:\\n\", classification_report(true_labels, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a440cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/continue.php: HTTPConnectionPool(host='etransfers.interac.ca-ssl.net', port=80): Max retries exceeded with url: /sh/2o05I9/bdesj/continue.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AAABD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/continue.php: HTTPConnectionPool(host='etransfers.interac.ca-ssl.net', port=80): Max retries exceeded with url: /sh/2o05I9/bdesj/continue.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA8A50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/continue.php: HTTPConnectionPool(host='etransfers.interac.ca-ssl.net', port=80): Max retries exceeded with url: /sh/2o05I9/bdesj/continue.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AAA750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://etransfers.interac.ca-ssl.net/sh/2o05I9/bdesj/continue.php: HTTPConnectionPool(host='etransfers.interac.ca-ssl.net', port=80): Max retries exceeded with url: /sh/2o05I9/bdesj/continue.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA9E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betterhealthsmoothies.com/Adobe/adobe-3D6/index.php: HTTPConnectionPool(host='betterhealthsmoothies.com', port=80): Max retries exceeded with url: /Adobe/adobe-3D6/index.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA9BD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betterhealthsmoothies.com/Adobe/adobe-3D6/index.php: HTTPConnectionPool(host='betterhealthsmoothies.com', port=80): Max retries exceeded with url: /Adobe/adobe-3D6/index.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA9390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betterhealthsmoothies.com/Adobe/adobe-3D6/index.php: HTTPConnectionPool(host='betterhealthsmoothies.com', port=80): Max retries exceeded with url: /Adobe/adobe-3D6/index.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA9950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betterhealthsmoothies.com/Adobe/adobe-3D6/index.php: HTTPConnectionPool(host='betterhealthsmoothies.com', port=80): Max retries exceeded with url: /Adobe/adobe-3D6/index.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AABA50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://lloydsbank.deregister-payee-secure-auth.com/Login.php: HTTPConnectionPool(host='lloydsbank.deregister-payee-secure-auth.com', port=80): Max retries exceeded with url: /Login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AAA990>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://lloydsbank.deregister-payee-secure-auth.com/Login.php: HTTPConnectionPool(host='lloydsbank.deregister-payee-secure-auth.com', port=80): Max retries exceeded with url: /Login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AAA550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://lloydsbank.deregister-payee-secure-auth.com/Login.php: HTTPConnectionPool(host='lloydsbank.deregister-payee-secure-auth.com', port=80): Max retries exceeded with url: /Login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA8150>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://lloydsbank.deregister-payee-secure-auth.com/Login.php: HTTPConnectionPool(host='lloydsbank.deregister-payee-secure-auth.com', port=80): Max retries exceeded with url: /Login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170AA8190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://archive.md: HTTPSConnectionPool(host='archive.md', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://archive.md: HTTPSConnectionPool(host='archive.md', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://archive.md: HTTPSConnectionPool(host='archive.md', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://archive.md: HTTPSConnectionPool(host='archive.md', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.shareholds.com/gbr/5df72f77-f30d-43da-8d9d-e1c679125f7f/fa33406d-2f65-4e1a-9b55-eac8ab765e48/7f38a394-8df7-452e-b2b6-8a3f35fb217d/login?id=ZE9hU3Z2M1ZNTkRlZTd2UnM3dmhreTBBcWF1ZkQ0VmFkNWJYOTl0K2FIN0gxUjQ5SUZCVU5JK25iSE5tWHJsQ0g1Q2dubjJvZFFhVTF1VGZ0eXpJaXk5YUpPRlVnYVcwSzJEeGZXR1RXOWhldFVTUUpvcjJBZjQxNDFHa3FPNnRFOThHZGJUMEt1MTJLUmE0T3ZYdWxUeTZBcUlRcFREeUdXMWhOY0crMDZiYmYzbDA2MGs4Y2JxeFVzU0ZBd0NzMG5SSUNVQjNkUGJ5OUdZZHdQQXVpL3BGd2xGeEZPb0ZqRW41R1VEMnN6N1R4clRUS2ZkOVNadGVKeUJYMG85T3ZYNDdJVEd2U291aUJaZnU2Mi9Rc3BvVjBMTk5Lbk4veWRhSUl5VVl0MjFMZ2h4R0ZmdEpnV0pQa0FmWkZiRFlqN0xmZzRaVDNoRHo2eisrOS9XNnR4NEEwZUg4NkhHYXhXYTZ3ZmZDdlh2SkJOeFB4eWs4eUwxVGZ2dEJwdVlB: HTTPConnectionPool(host='www.shareholds.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.shareholds.com/gbr/5df72f77-f30d-43da-8d9d-e1c679125f7f/fa33406d-2f65-4e1a-9b55-eac8ab765e48/7f38a394-8df7-452e-b2b6-8a3f35fb217d/login?id=ZE9hU3Z2M1ZNTkRlZTd2UnM3dmhreTBBcWF1ZkQ0VmFkNWJYOTl0K2FIN0gxUjQ5SUZCVU5JK25iSE5tWHJsQ0g1Q2dubjJvZFFhVTF1VGZ0eXpJaXk5YUpPRlVnYVcwSzJEeGZXR1RXOWhldFVTUUpvcjJBZjQxNDFHa3FPNnRFOThHZGJUMEt1MTJLUmE0T3ZYdWxUeTZBcUlRcFREeUdXMWhOY0crMDZiYmYzbDA2MGs4Y2JxeFVzU0ZBd0NzMG5SSUNVQjNkUGJ5OUdZZHdQQXVpL3BGd2xGeEZPb0ZqRW41R1VEMnN6N1R4clRUS2ZkOVNadGVKeUJYMG85T3ZYNDdJVEd2U291aUJaZnU2Mi9Rc3BvVjBMTk5Lbk4veWRhSUl5VVl0MjFMZ2h4R0ZmdEpnV0pQa0FmWkZiRFlqN0xmZzRaVDNoRHo2eisrOS9XNnR4NEEwZUg4NkhHYXhXYTZ3ZmZDdlh2SkJOeFB4eWs4eUwxVGZ2dEJwdVlB: HTTPConnectionPool(host='www.shareholds.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.shareholds.com/gbr/5df72f77-f30d-43da-8d9d-e1c679125f7f/fa33406d-2f65-4e1a-9b55-eac8ab765e48/7f38a394-8df7-452e-b2b6-8a3f35fb217d/login?id=ZE9hU3Z2M1ZNTkRlZTd2UnM3dmhreTBBcWF1ZkQ0VmFkNWJYOTl0K2FIN0gxUjQ5SUZCVU5JK25iSE5tWHJsQ0g1Q2dubjJvZFFhVTF1VGZ0eXpJaXk5YUpPRlVnYVcwSzJEeGZXR1RXOWhldFVTUUpvcjJBZjQxNDFHa3FPNnRFOThHZGJUMEt1MTJLUmE0T3ZYdWxUeTZBcUlRcFREeUdXMWhOY0crMDZiYmYzbDA2MGs4Y2JxeFVzU0ZBd0NzMG5SSUNVQjNkUGJ5OUdZZHdQQXVpL3BGd2xGeEZPb0ZqRW41R1VEMnN6N1R4clRUS2ZkOVNadGVKeUJYMG85T3ZYNDdJVEd2U291aUJaZnU2Mi9Rc3BvVjBMTk5Lbk4veWRhSUl5VVl0MjFMZ2h4R0ZmdEpnV0pQa0FmWkZiRFlqN0xmZzRaVDNoRHo2eisrOS9XNnR4NEEwZUg4NkhHYXhXYTZ3ZmZDdlh2SkJOeFB4eWs4eUwxVGZ2dEJwdVlB: HTTPConnectionPool(host='www.shareholds.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.shareholds.com/gbr/5df72f77-f30d-43da-8d9d-e1c679125f7f/fa33406d-2f65-4e1a-9b55-eac8ab765e48/7f38a394-8df7-452e-b2b6-8a3f35fb217d/login?id=ZE9hU3Z2M1ZNTkRlZTd2UnM3dmhreTBBcWF1ZkQ0VmFkNWJYOTl0K2FIN0gxUjQ5SUZCVU5JK25iSE5tWHJsQ0g1Q2dubjJvZFFhVTF1VGZ0eXpJaXk5YUpPRlVnYVcwSzJEeGZXR1RXOWhldFVTUUpvcjJBZjQxNDFHa3FPNnRFOThHZGJUMEt1MTJLUmE0T3ZYdWxUeTZBcUlRcFREeUdXMWhOY0crMDZiYmYzbDA2MGs4Y2JxeFVzU0ZBd0NzMG5SSUNVQjNkUGJ5OUdZZHdQQXVpL3BGd2xGeEZPb0ZqRW41R1VEMnN6N1R4clRUS2ZkOVNadGVKeUJYMG85T3ZYNDdJVEd2U291aUJaZnU2Mi9Rc3BvVjBMTk5Lbk4veWRhSUl5VVl0MjFMZ2h4R0ZmdEpnV0pQa0FmWkZiRFlqN0xmZzRaVDNoRHo2eisrOS9XNnR4NEEwZUg4NkhHYXhXYTZ3ZmZDdlh2SkJOeFB4eWs4eUwxVGZ2dEJwdVlB: HTTPConnectionPool(host='www.shareholds.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://sub-166-141-241.myvzw.com: HTTPConnectionPool(host='sub-166-141-241.myvzw.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE6D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sub-166-141-241.myvzw.com: HTTPConnectionPool(host='sub-166-141-241.myvzw.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sub-166-141-241.myvzw.com: HTTPConnectionPool(host='sub-166-141-241.myvzw.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF3D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sub-166-141-241.myvzw.com: HTTPConnectionPool(host='sub-166-141-241.myvzw.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE4D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://hgdggdgfghygsugfytsfgssytstys.gq/83cbc: HTTPConnectionPool(host='hgdggdgfghygsugfytsfgssytstys.gq', port=80): Max retries exceeded with url: /83cbc (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DC590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hgdggdgfghygsugfytsfgssytstys.gq/83cbc: HTTPConnectionPool(host='hgdggdgfghygsugfytsfgssytstys.gq', port=80): Max retries exceeded with url: /83cbc (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hgdggdgfghygsugfytsfgssytstys.gq/83cbc: HTTPConnectionPool(host='hgdggdgfghygsugfytsfgssytstys.gq', port=80): Max retries exceeded with url: /83cbc (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hgdggdgfghygsugfytsfgssytstys.gq/83cbc: HTTPConnectionPool(host='hgdggdgfghygsugfytsfgssytstys.gq', port=80): Max retries exceeded with url: /83cbc (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE7D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.commbanknetcode.com: HTTPConnectionPool(host='www.commbanknetcode.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.commbanknetcode.com: HTTPConnectionPool(host='www.commbanknetcode.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF710>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.commbanknetcode.com: HTTPConnectionPool(host='www.commbanknetcode.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DC590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.commbanknetcode.com: HTTPConnectionPool(host='www.commbanknetcode.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DF650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cn-south-1.myhuaweicloud.cn: HTTPConnectionPool(host='cn-south-1.myhuaweicloud.cn', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709F66D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cn-south-1.myhuaweicloud.cn: HTTPConnectionPool(host='cn-south-1.myhuaweicloud.cn', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cn-south-1.myhuaweicloud.cn: HTTPConnectionPool(host='cn-south-1.myhuaweicloud.cn', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DCF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cn-south-1.myhuaweicloud.cn: HTTPConnectionPool(host='cn-south-1.myhuaweicloud.cn', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DDF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coianasbsbselog.azurewebsites.net: HTTPConnectionPool(host='coianasbsbselog.azurewebsites.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DCA90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coianasbsbselog.azurewebsites.net: HTTPConnectionPool(host='coianasbsbselog.azurewebsites.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DCD50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coianasbsbselog.azurewebsites.net: HTTPConnectionPool(host='coianasbsbselog.azurewebsites.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DCA50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coianasbsbselog.azurewebsites.net: HTTPConnectionPool(host='coianasbsbselog.azurewebsites.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DE0D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mobile.kptncook.com: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://mobile.kptncook.com: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://mobile.kptncook.com: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://mobile.kptncook.com: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://6sc.co: HTTPConnectionPool(host='6sc.co', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DDD50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://6sc.co: HTTPConnectionPool(host='6sc.co', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DCD50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://6sc.co: HTTPConnectionPool(host='6sc.co', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DFED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://6sc.co: HTTPConnectionPool(host='6sc.co', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DFED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://orthovirginia-zsb2.cloud.tanium.com: HTTPConnectionPool(host='orthovirginia-zsb2.cloud.tanium.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001217084F750>, 'Connection to orthovirginia-zsb2.cloud.tanium.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://orthovirginia-zsb2.cloud.tanium.com: HTTPConnectionPool(host='orthovirginia-zsb2.cloud.tanium.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001217084F590>, 'Connection to orthovirginia-zsb2.cloud.tanium.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://orthovirginia-zsb2.cloud.tanium.com: HTTPConnectionPool(host='orthovirginia-zsb2.cloud.tanium.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012170835B50>, 'Connection to orthovirginia-zsb2.cloud.tanium.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://orthovirginia-zsb2.cloud.tanium.com: HTTPConnectionPool(host='orthovirginia-zsb2.cloud.tanium.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001217081AD90>, 'Connection to orthovirginia-zsb2.cloud.tanium.com timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://payleboncoinid.site: HTTPConnectionPool(host='payleboncoinid.site', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B3E90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://payleboncoinid.site: HTTPConnectionPool(host='payleboncoinid.site', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B3A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://payleboncoinid.site: HTTPConnectionPool(host='payleboncoinid.site', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B3A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://payleboncoinid.site: HTTPConnectionPool(host='payleboncoinid.site', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B1A50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bonuseforex.com/help/contact/9417940251527349: HTTPConnectionPool(host='bonuseforex.com', port=80): Max retries exceeded with url: /help/contact/9417940251527349 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B1B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bonuseforex.com/help/contact/9417940251527349: HTTPConnectionPool(host='bonuseforex.com', port=80): Max retries exceeded with url: /help/contact/9417940251527349 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B1B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bonuseforex.com/help/contact/9417940251527349: HTTPConnectionPool(host='bonuseforex.com', port=80): Max retries exceeded with url: /help/contact/9417940251527349 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170751950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bonuseforex.com/help/contact/9417940251527349: HTTPConnectionPool(host='bonuseforex.com', port=80): Max retries exceeded with url: /help/contact/9417940251527349 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121707B0890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://192714-ipv4v6.gr.global.aa-rt.sharepoint.com: HTTPConnectionPool(host='192714-ipv4v6.gr.global.aa-rt.sharepoint.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://192714-ipv4v6.gr.global.aa-rt.sharepoint.com: HTTPConnectionPool(host='192714-ipv4v6.gr.global.aa-rt.sharepoint.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://192714-ipv4v6.gr.global.aa-rt.sharepoint.com: HTTPConnectionPool(host='192714-ipv4v6.gr.global.aa-rt.sharepoint.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://alerts.galileo.dev1-ext.chmfin.com: HTTPConnectionPool(host='alerts.galileo.dev1-ext.chmfin.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://alerts.galileo.dev1-ext.chmfin.com: HTTPConnectionPool(host='alerts.galileo.dev1-ext.chmfin.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://alerts.galileo.dev1-ext.chmfin.com: HTTPConnectionPool(host='alerts.galileo.dev1-ext.chmfin.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://alerts.galileo.dev1-ext.chmfin.com: HTTPConnectionPool(host='alerts.galileo.dev1-ext.chmfin.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://ee-checksecure.com/account/index?ac=ee: HTTPConnectionPool(host='ee-checksecure.com', port=80): Max retries exceeded with url: /account/index?ac=ee (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170751390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ee-checksecure.com/account/index?ac=ee: HTTPConnectionPool(host='ee-checksecure.com', port=80): Max retries exceeded with url: /account/index?ac=ee (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170752C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ee-checksecure.com/account/index?ac=ee: HTTPConnectionPool(host='ee-checksecure.com', port=80): Max retries exceeded with url: /account/index?ac=ee (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170752C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ee-checksecure.com/account/index?ac=ee: HTTPConnectionPool(host='ee-checksecure.com', port=80): Max retries exceeded with url: /account/index?ac=ee (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170752C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17688\\1589813510.py:31: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://cc76387.tmweb.ru/0f19a279bcab94f/region.php?particulier: HTTPConnectionPool(host='cc76387.tmweb.ru', port=80): Max retries exceeded with url: /0f19a279bcab94f/region.php?particulier (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217073F810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cc76387.tmweb.ru/0f19a279bcab94f/region.php?particulier: HTTPConnectionPool(host='cc76387.tmweb.ru', port=80): Max retries exceeded with url: /0f19a279bcab94f/region.php?particulier (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217073EC50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cc76387.tmweb.ru/0f19a279bcab94f/region.php?particulier: HTTPConnectionPool(host='cc76387.tmweb.ru', port=80): Max retries exceeded with url: /0f19a279bcab94f/region.php?particulier (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217073D0D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://cc76387.tmweb.ru/0f19a279bcab94f/region.php?particulier: HTTPConnectionPool(host='cc76387.tmweb.ru', port=80): Max retries exceeded with url: /0f19a279bcab94f/region.php?particulier (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217073D0D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://notifications.getxray.app: HTTPSConnectionPool(host='notifications.getxray.app', port=443): Max retries exceeded with url: /en (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x00000121709AC310>, 'Connection to notifications.getxray.app timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://kumpulan1-berita-viral-update-malaysia.myhomeofficial.com: HTTPSConnectionPool(host='kumpulan1-berita-viral-update-malaysia.myhomeofficial.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://kumpulan1-berita-viral-update-malaysia.myhomeofficial.com: HTTPSConnectionPool(host='kumpulan1-berita-viral-update-malaysia.myhomeofficial.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://kumpulan1-berita-viral-update-malaysia.myhomeofficial.com: HTTPSConnectionPool(host='kumpulan1-berita-viral-update-malaysia.myhomeofficial.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://kumpulan1-berita-viral-update-malaysia.myhomeofficial.com: HTTPSConnectionPool(host='kumpulan1-berita-viral-update-malaysia.myhomeofficial.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://outlook.recognitionnow.com: HTTPSConnectionPool(host='outlook.recognitionnow.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://outlook.recognitionnow.com: HTTPSConnectionPool(host='outlook.recognitionnow.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://outlook.recognitionnow.com: HTTPSConnectionPool(host='outlook.recognitionnow.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://outlook.recognitionnow.com: HTTPSConnectionPool(host='outlook.recognitionnow.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.posby.gq/m&tbankaccess: HTTPConnectionPool(host='www.posby.gq', port=80): Max retries exceeded with url: /m&tbankaccess (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170794A90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.posby.gq/m&tbankaccess: HTTPConnectionPool(host='www.posby.gq', port=80): Max retries exceeded with url: /m&tbankaccess (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217093C590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.posby.gq/m&tbankaccess: HTTPConnectionPool(host='www.posby.gq', port=80): Max retries exceeded with url: /m&tbankaccess (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217094C450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.posby.gq/m&tbankaccess: HTTPConnectionPool(host='www.posby.gq', port=80): Max retries exceeded with url: /m&tbankaccess (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001217093C8D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://discordapp.click/nitro/boost: HTTPConnectionPool(host='discordapp.click', port=80): Max retries exceeded with url: /nitro/boost (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C4390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://discordapp.click/nitro/boost: HTTPConnectionPool(host='discordapp.click', port=80): Max retries exceeded with url: /nitro/boost (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C7410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://discordapp.click/nitro/boost: HTTPConnectionPool(host='discordapp.click', port=80): Max retries exceeded with url: /nitro/boost (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C4A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://discordapp.click/nitro/boost: HTTPConnectionPool(host='discordapp.click', port=80): Max retries exceeded with url: /nitro/boost (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C4750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.isupport.us-9bq.ru/i/sing/X6fj: HTTPConnectionPool(host='www.isupport.us-9bq.ru', port=80): Max retries exceeded with url: /i/sing/X6fj (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C7950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.isupport.us-9bq.ru/i/sing/X6fj: HTTPConnectionPool(host='www.isupport.us-9bq.ru', port=80): Max retries exceeded with url: /i/sing/X6fj (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C7290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.isupport.us-9bq.ru/i/sing/X6fj: HTTPConnectionPool(host='www.isupport.us-9bq.ru', port=80): Max retries exceeded with url: /i/sing/X6fj (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C42D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.isupport.us-9bq.ru/i/sing/X6fj: HTTPConnectionPool(host='www.isupport.us-9bq.ru', port=80): Max retries exceeded with url: /i/sing/X6fj (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C5390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://id-white-vulture-benfrejchadi350704.codeanyapp.com/ee/dhI/DH2tAyUe9AsUx7b822: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error fetching or parsing URL http://id-white-vulture-benfrejchadi350704.codeanyapp.com/ee/dhI/DH2tAyUe9AsUx7b822: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error fetching or parsing URL http://id-white-vulture-benfrejchadi350704.codeanyapp.com/ee/dhI/DH2tAyUe9AsUx7b822: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error fetching or parsing URL http://id-white-vulture-benfrejchadi350704.codeanyapp.com/ee/dhI/DH2tAyUe9AsUx7b822: HTTPConnectionPool(host='id-white-vulture-benfrejchadi350704.codeanyapp.com', port=80): Max retries exceeded with url: /ee/dhI/DH2tAyUe9AsUx7b822 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001217094FF50>, 'Connection to id-white-vulture-benfrejchadi350704.codeanyapp.com timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://frescofish.in/blessings/english: HTTPConnectionPool(host='frescofish.in', port=80): Max retries exceeded with url: /blessings/english (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E1E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://frescofish.in/blessings/english: HTTPConnectionPool(host='frescofish.in', port=80): Max retries exceeded with url: /blessings/english (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E2090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://frescofish.in/blessings/english: HTTPConnectionPool(host='frescofish.in', port=80): Max retries exceeded with url: /blessings/english (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E1850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://frescofish.in/blessings/english: HTTPConnectionPool(host='frescofish.in', port=80): Max retries exceeded with url: /blessings/english (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E1D50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://buluajib.com/.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=: HTTPConnectionPool(host='buluajib.com', port=80): Max retries exceeded with url: /.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170819D50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://buluajib.com/.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=: HTTPConnectionPool(host='buluajib.com', port=80): Max retries exceeded with url: /.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DFC90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://buluajib.com/.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=: HTTPConnectionPool(host='buluajib.com', port=80): Max retries exceeded with url: /.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E1390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://buluajib.com/.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=: HTTPConnectionPool(host='buluajib.com', port=80): Max retries exceeded with url: /.well-known/.well-known/well-known/cmd-login=022b914117b67e957b6068f551dd9ba8/?newsid=4417464081MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&loginpage=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=&reff=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI=MGVkZTM2OWI0OGUyMTg5MmY0YTZkYTUwNTU0MGNkYjI= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001218DAFBF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.mtbank.hemmorx.com/verif.php: HTTPConnectionPool(host='www.mtbank.hemmorx.com', port=80): Max retries exceeded with url: /verif.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E3610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.mtbank.hemmorx.com/verif.php: HTTPConnectionPool(host='www.mtbank.hemmorx.com', port=80): Max retries exceeded with url: /verif.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121709DD690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.mtbank.hemmorx.com/verif.php: HTTPConnectionPool(host='www.mtbank.hemmorx.com', port=80): Max retries exceeded with url: /verif.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708E1690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.mtbank.hemmorx.com/verif.php: HTTPConnectionPool(host='www.mtbank.hemmorx.com', port=80): Max retries exceeded with url: /verif.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170819A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sawiou76.blogspot.com.by/2023/11: HTTPConnectionPool(host='sawiou76.blogspot.com.by', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://sawiou76.blogspot.com.by/2023/11: HTTPConnectionPool(host='sawiou76.blogspot.com.by', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://sawiou76.blogspot.com.by/2023/11: HTTPConnectionPool(host='sawiou76.blogspot.com.by', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://sawiou76.blogspot.com.by/2023/11: HTTPConnectionPool(host='sawiou76.blogspot.com.by', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://customerportal.suez.co.uk: HTTPSConnectionPool(host='customerportal.suez.co.uk', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://customerportal.suez.co.uk: HTTPSConnectionPool(host='customerportal.suez.co.uk', port=443): Read timed out. (read timeout=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://80g10hb.cn: HTTPConnectionPool(host='www.80g10hb.cn', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://80g10hb.cn: HTTPConnectionPool(host='www.80g10hb.cn', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://80g10hb.cn: HTTPConnectionPool(host='www.80g10hb.cn', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://80g10hb.cn: HTTPConnectionPool(host='www.80g10hb.cn', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://grapecreek.com: HTTPSConnectionPool(host='grapecreek.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://grapecreek.com: HTTPSConnectionPool(host='www.grapecreek.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://gate2.murrelektronik.de: HTTPConnectionPool(host='gate2.murrelektronik.de', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121708E3910>, 'Connection to gate2.murrelektronik.de timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://gate2.murrelektronik.de: HTTPConnectionPool(host='gate2.murrelektronik.de', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121707C5310>, 'Connection to gate2.murrelektronik.de timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://gate2.murrelektronik.de: HTTPConnectionPool(host='gate2.murrelektronik.de', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121708C7010>, 'Connection to gate2.murrelektronik.de timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://gate2.murrelektronik.de: HTTPConnectionPool(host='gate2.murrelektronik.de', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121707F1250>, 'Connection to gate2.murrelektronik.de timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://v3fbryvxiunkkj.liusanjie.cc/index/usps/index.html: HTTPConnectionPool(host='v3fbryvxiunkkj.liusanjie.cc', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012170A26850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://v3fbryvxiunkkj.liusanjie.cc/index/usps/index.html: HTTPConnectionPool(host='v3fbryvxiunkkj.liusanjie.cc', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C5150>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://v3fbryvxiunkkj.liusanjie.cc/index/usps/index.html: HTTPConnectionPool(host='v3fbryvxiunkkj.liusanjie.cc', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C5C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://v3fbryvxiunkkj.liusanjie.cc/index/usps/index.html: HTTPConnectionPool(host='v3fbryvxiunkkj.liusanjie.cc', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708C43D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://petebellas.com/secure/verification.php: HTTPConnectionPool(host='petebellas.com', port=80): Max retries exceeded with url: /secure/verification.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121708C7BD0>, 'Connection to petebellas.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://petebellas.com/secure/verification.php: HTTPConnectionPool(host='petebellas.com', port=80): Max retries exceeded with url: /secure/verification.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121707C7010>, 'Connection to petebellas.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://petebellas.com/secure/verification.php: HTTPConnectionPool(host='petebellas.com', port=80): Max retries exceeded with url: /secure/verification.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121708E39D0>, 'Connection to petebellas.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://petebellas.com/secure/verification.php: HTTPConnectionPool(host='petebellas.com', port=80): Max retries exceeded with url: /secure/verification.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121707F2550>, 'Connection to petebellas.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://mailin.yahoodns.net: HTTPConnectionPool(host='mailin.yahoodns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCEED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mailin.yahoodns.net: HTTPConnectionPool(host='mailin.yahoodns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCD4D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mailin.yahoodns.net: HTTPConnectionPool(host='mailin.yahoodns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCF810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mailin.yahoodns.net: HTTPConnectionPool(host='mailin.yahoodns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCF950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.hsbc.co.uk-global-secure.review/index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https: HTTPConnectionPool(host='www.hsbc.co.uk-global-secure.review', port=80): Max retries exceeded with url: /index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD30C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.hsbc.co.uk-global-secure.review/index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https: HTTPConnectionPool(host='www.hsbc.co.uk-global-secure.review', port=80): Max retries exceeded with url: /index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD30450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.hsbc.co.uk-global-secure.review/index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https: HTTPConnectionPool(host='www.hsbc.co.uk-global-secure.review', port=80): Max retries exceeded with url: /index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCF450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.hsbc.co.uk-global-secure.review/index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https: HTTPConnectionPool(host='www.hsbc.co.uk-global-secure.review', port=80): Max retries exceeded with url: /index.php/false/false/py1n.html/discovercard.com/dfs/accounthome/summary/-www.schwab.com/secure.accurint.com/unfcu2.org/login1/wachovia.com/myaccounts.aspx/investing.schwab.com/secure/schwab/https (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCDB50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://mos.cms.futurecdn.net: HTTPConnectionPool(host='mos.cms.futurecdn.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD32110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mos.cms.futurecdn.net: HTTPConnectionPool(host='mos.cms.futurecdn.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD31B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mos.cms.futurecdn.net: HTTPConnectionPool(host='mos.cms.futurecdn.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD324D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mos.cms.futurecdn.net: HTTPConnectionPool(host='mos.cms.futurecdn.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD32C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.oldschool.com-zs.ru/m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3: HTTPConnectionPool(host='secure.oldschool.com-zs.ru', port=80): Max retries exceeded with url: /m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD32CD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.oldschool.com-zs.ru/m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3: HTTPConnectionPool(host='secure.oldschool.com-zs.ru', port=80): Max retries exceeded with url: /m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD30690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.oldschool.com-zs.ru/m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3: HTTPConnectionPool(host='secure.oldschool.com-zs.ru', port=80): Max retries exceeded with url: /m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD30690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.oldschool.com-zs.ru/m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3: HTTPConnectionPool(host='secure.oldschool.com-zs.ru', port=80): Max retries exceeded with url: /m=forum/forums.ws889,6465776862,77684365536425,56462869373634,3 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FD32DD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.ddiggitalcu.us/dcu/otp.html: HTTPConnectionPool(host='www.ddiggitalcu.us', port=80): Max retries exceeded with url: /dcu/otp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDE4210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.ddiggitalcu.us/dcu/otp.html: HTTPConnectionPool(host='www.ddiggitalcu.us', port=80): Max retries exceeded with url: /dcu/otp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDE7510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.ddiggitalcu.us/dcu/otp.html: HTTPConnectionPool(host='www.ddiggitalcu.us', port=80): Max retries exceeded with url: /dcu/otp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDE4850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.ddiggitalcu.us/dcu/otp.html: HTTPConnectionPool(host='www.ddiggitalcu.us', port=80): Max retries exceeded with url: /dcu/otp.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDE7450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nice-gauss.198-23-207-203.plesk.page/p/92c78: HTTPConnectionPool(host='nice-gauss.198-23-207-203.plesk.page', port=80): Max retries exceeded with url: /p/92c78 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FD305D0>, 'Connection to nice-gauss.198-23-207-203.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://nice-gauss.198-23-207-203.plesk.page/p/92c78: HTTPConnectionPool(host='nice-gauss.198-23-207-203.plesk.page', port=80): Max retries exceeded with url: /p/92c78 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FDCEE50>, 'Connection to nice-gauss.198-23-207-203.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://nice-gauss.198-23-207-203.plesk.page/p/92c78: HTTPConnectionPool(host='nice-gauss.198-23-207-203.plesk.page', port=80): Max retries exceeded with url: /p/92c78 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FDB7E50>, 'Connection to nice-gauss.198-23-207-203.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://nice-gauss.198-23-207-203.plesk.page/p/92c78: HTTPConnectionPool(host='nice-gauss.198-23-207-203.plesk.page', port=80): Max retries exceeded with url: /p/92c78 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216F93B750>, 'Connection to nice-gauss.198-23-207-203.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://favouritehardship.com/file/Office365/view: HTTPConnectionPool(host='favouritehardship.com', port=80): Max retries exceeded with url: /file/Office365/view (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE085D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://favouritehardship.com/file/Office365/view: HTTPConnectionPool(host='favouritehardship.com', port=80): Max retries exceeded with url: /file/Office365/view (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCCA90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://favouritehardship.com/file/Office365/view: HTTPConnectionPool(host='favouritehardship.com', port=80): Max retries exceeded with url: /file/Office365/view (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCC7D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://favouritehardship.com/file/Office365/view: HTTPConnectionPool(host='favouritehardship.com', port=80): Max retries exceeded with url: /file/Office365/view (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCE290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://vsa07.thrivenextgen.com: HTTPConnectionPool(host='vsa07.thrivenextgen.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FDCF790>, 'Connection to vsa07.thrivenextgen.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://vsa07.thrivenextgen.com: HTTPConnectionPool(host='vsa07.thrivenextgen.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216F93B310>, 'Connection to vsa07.thrivenextgen.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://vsa07.thrivenextgen.com: HTTPConnectionPool(host='vsa07.thrivenextgen.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FD33910>, 'Connection to vsa07.thrivenextgen.com timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://vsa07.thrivenextgen.com: HTTPConnectionPool(host='vsa07.thrivenextgen.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FDB4310>, 'Connection to vsa07.thrivenextgen.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://sucursalpersonas.transacionesbancolombia.com/mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw=: HTTPConnectionPool(host='sucursalpersonas.transacionesbancolombia.com', port=80): Max retries exceeded with url: /mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDE5810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sucursalpersonas.transacionesbancolombia.com/mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw=: HTTPConnectionPool(host='sucursalpersonas.transacionesbancolombia.com', port=80): Max retries exceeded with url: /mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE09C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sucursalpersonas.transacionesbancolombia.com/mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw=: HTTPConnectionPool(host='sucursalpersonas.transacionesbancolombia.com', port=80): Max retries exceeded with url: /mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE09050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://sucursalpersonas.transacionesbancolombia.com/mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw=: HTTPConnectionPool(host='sucursalpersonas.transacionesbancolombia.com', port=80): Max retries exceeded with url: /mua/USER?scis=HGXmnhj015fu/mNq9r5ZriAKtHK71zoLgJkOib89pnw= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE08690>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://b0a2805368f274241b7b34a638.tstyle.de/DE-Hrf751Pmjh/znte0mti=: HTTPConnectionPool(host='b0a2805368f274241b7b34a638.tstyle.de', port=80): Max retries exceeded with url: /DE-Hrf751Pmjh/znte0mti= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F939510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://b0a2805368f274241b7b34a638.tstyle.de/DE-Hrf751Pmjh/znte0mti=: HTTPConnectionPool(host='b0a2805368f274241b7b34a638.tstyle.de', port=80): Max retries exceeded with url: /DE-Hrf751Pmjh/znte0mti= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F93B950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://b0a2805368f274241b7b34a638.tstyle.de/DE-Hrf751Pmjh/znte0mti=: HTTPConnectionPool(host='b0a2805368f274241b7b34a638.tstyle.de', port=80): Max retries exceeded with url: /DE-Hrf751Pmjh/znte0mti= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F9387D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://b0a2805368f274241b7b34a638.tstyle.de/DE-Hrf751Pmjh/znte0mti=: HTTPConnectionPool(host='b0a2805368f274241b7b34a638.tstyle.de', port=80): Max retries exceeded with url: /DE-Hrf751Pmjh/znte0mti= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F9389D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://in.akadns.net: HTTPConnectionPool(host='in.akadns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCF710>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://in.akadns.net: HTTPConnectionPool(host='in.akadns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCF610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://in.akadns.net: HTTPConnectionPool(host='in.akadns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCCAD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://in.akadns.net: HTTPConnectionPool(host='in.akadns.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FDCD710>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://immb.com.au/wells: HTTPConnectionPool(host='immb.com.au', port=80): Max retries exceeded with url: /wells (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE24590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://immb.com.au/wells: HTTPConnectionPool(host='immb.com.au', port=80): Max retries exceeded with url: /wells (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE256D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://immb.com.au/wells: HTTPConnectionPool(host='immb.com.au', port=80): Max retries exceeded with url: /wells (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE24490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://immb.com.au/wells: HTTPConnectionPool(host='immb.com.au', port=80): Max retries exceeded with url: /wells (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE24490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.myf2b.com: HTTPSConnectionPool(host='www.myf2b.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.myf2b.com: HTTPSConnectionPool(host='www.myf2b.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.myf2b.com: HTTPSConnectionPool(host='www.myf2b.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.myf2b.com: HTTPSConnectionPool(host='www.myf2b.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://api.mcspserver.net: HTTPConnectionPool(host='api.mcspserver.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216F8EBED0>, 'Connection to api.mcspserver.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://api.mcspserver.net: HTTPConnectionPool(host='api.mcspserver.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216F8EB310>, 'Connection to api.mcspserver.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://api.mcspserver.net: HTTPConnectionPool(host='api.mcspserver.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FD9C550>, 'Connection to api.mcspserver.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://api.mcspserver.net: HTTPConnectionPool(host='api.mcspserver.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FE26610>, 'Connection to api.mcspserver.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://static.public.inf0.net: HTTPConnectionPool(host='static.public.inf0.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE65110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://static.public.inf0.net: HTTPConnectionPool(host='static.public.inf0.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE64ED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://static.public.inf0.net: HTTPConnectionPool(host='static.public.inf0.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE67C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://static.public.inf0.net: HTTPConnectionPool(host='static.public.inf0.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216FE66C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://delexpress.org: HTTPConnectionPool(host='delexpress.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8EBF50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://delexpress.org: HTTPConnectionPool(host='delexpress.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8EA210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://delexpress.org: HTTPConnectionPool(host='delexpress.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8E8610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://delexpress.org: HTTPConnectionPool(host='delexpress.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8EA950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.matthewmantey.com/t/m&t/home/login.php?auth=3D9cb48ed474e2c0=: HTTPConnectionPool(host='www.matthewmantey.com', port=80): Max retries exceeded with url: /t/m&t/home/login.php?auth=3D9cb48ed474e2c0= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8EA490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.matthewmantey.com/t/m&t/home/login.php?auth=3D9cb48ed474e2c0=: HTTPConnectionPool(host='www.matthewmantey.com', port=80): Max retries exceeded with url: /t/m&t/home/login.php?auth=3D9cb48ed474e2c0= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8E9990>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.matthewmantey.com/t/m&t/home/login.php?auth=3D9cb48ed474e2c0=: HTTPConnectionPool(host='www.matthewmantey.com', port=80): Max retries exceeded with url: /t/m&t/home/login.php?auth=3D9cb48ed474e2c0= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8EBE50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.matthewmantey.com/t/m&t/home/login.php?auth=3D9cb48ed474e2c0=: HTTPConnectionPool(host='www.matthewmantey.com', port=80): Max retries exceeded with url: /t/m&t/home/login.php?auth=3D9cb48ed474e2c0= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F8E8290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.dr.com.tr: HTTPSConnectionPool(host='www.dr.com.tr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.dr.com.tr: HTTPSConnectionPool(host='www.dr.com.tr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://connect-formation.fr/wordpress/wp-includes/images/smilies/Cloud/customer_center/user-287715/3dCard.php: HTTPSConnectionPool(host='connect-formation.fr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://connect-formation.fr/wordpress/wp-includes/images/smilies/Cloud/customer_center/user-287715/3dCard.php: HTTPSConnectionPool(host='connect-formation.fr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://connect-formation.fr/wordpress/wp-includes/images/smilies/Cloud/customer_center/user-287715/3dCard.php: HTTPSConnectionPool(host='connect-formation.fr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://connect-formation.fr/wordpress/wp-includes/images/smilies/Cloud/customer_center/user-287715/3dCard.php: HTTPSConnectionPool(host='connect-formation.fr', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://aws.kros.cloud: HTTPConnectionPool(host='aws.kros.cloud', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC97290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://aws.kros.cloud: HTTPConnectionPool(host='aws.kros.cloud', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC95FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://aws.kros.cloud: HTTPConnectionPool(host='aws.kros.cloud', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC96E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://aws.kros.cloud: HTTPConnectionPool(host='aws.kros.cloud', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC960D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ascend-studios.org/paypal: HTTPConnectionPool(host='ascend-studios.org', port=80): Max retries exceeded with url: /paypal (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC95010>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ascend-studios.org/paypal: HTTPConnectionPool(host='ascend-studios.org', port=80): Max retries exceeded with url: /paypal (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC94590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ascend-studios.org/paypal: HTTPConnectionPool(host='ascend-studios.org', port=80): Max retries exceeded with url: /paypal (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC97E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://ascend-studios.org/paypal: HTTPConnectionPool(host='ascend-studios.org', port=80): Max retries exceeded with url: /paypal (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC94450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://amycoley.com/William%20D%20Rathbun/mazon/amazon: HTTPConnectionPool(host='amycoley.com', port=80): Max retries exceeded with url: /William%20D%20Rathbun/mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC96B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://amycoley.com/William%20D%20Rathbun/mazon/amazon: HTTPConnectionPool(host='amycoley.com', port=80): Max retries exceeded with url: /William%20D%20Rathbun/mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC94650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://amycoley.com/William%20D%20Rathbun/mazon/amazon: HTTPConnectionPool(host='amycoley.com', port=80): Max retries exceeded with url: /William%20D%20Rathbun/mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC94E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://amycoley.com/William%20D%20Rathbun/mazon/amazon: HTTPConnectionPool(host='amycoley.com', port=80): Max retries exceeded with url: /William%20D%20Rathbun/mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC96210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://10001-interac.com/sh/239289/bdesj/lastdesj.php: HTTPConnectionPool(host='10001-interac.com', port=80): Max retries exceeded with url: /sh/239289/bdesj/lastdesj.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC85750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://10001-interac.com/sh/239289/bdesj/lastdesj.php: HTTPConnectionPool(host='10001-interac.com', port=80): Max retries exceeded with url: /sh/239289/bdesj/lastdesj.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DCD4350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://10001-interac.com/sh/239289/bdesj/lastdesj.php: HTTPConnectionPool(host='10001-interac.com', port=80): Max retries exceeded with url: /sh/239289/bdesj/lastdesj.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DC86C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://10001-interac.com/sh/239289/bdesj/lastdesj.php: HTTPConnectionPool(host='10001-interac.com', port=80): Max retries exceeded with url: /sh/239289/bdesj/lastdesj.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216DCD5110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://wallet-api.urbanairship.com: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "Error fetching or parsing URL http://wallet-api.urbanairship.com: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error fetching or parsing URL http://wallet-api.urbanairship.com: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://wallet-api.urbanairship.com: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error fetching or parsing URL http://profilefacebook-1139800146.agencija-klopotec.si/profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889: HTTPConnectionPool(host='profilefacebook-1139800146.agencija-klopotec.si', port=80): Max retries exceeded with url: /profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DFA90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://profilefacebook-1139800146.agencija-klopotec.si/profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889: HTTPConnectionPool(host='profilefacebook-1139800146.agencija-klopotec.si', port=80): Max retries exceeded with url: /profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DC5D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://profilefacebook-1139800146.agencija-klopotec.si/profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889: HTTPConnectionPool(host='profilefacebook-1139800146.agencija-klopotec.si', port=80): Max retries exceeded with url: /profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DD7D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://profilefacebook-1139800146.agencija-klopotec.si/profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889: HTTPConnectionPool(host='profilefacebook-1139800146.agencija-klopotec.si', port=80): Max retries exceeded with url: /profile.html?countuser=c8f4a601226e1a16a48bab97ecf51889 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DC050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://music-game.auth.visa.com: HTTPConnectionPool(host='music-game.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DCF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://music-game.auth.visa.com: HTTPConnectionPool(host='music-game.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DCF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://music-game.auth.visa.com: HTTPConnectionPool(host='music-game.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DCF90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://music-game.auth.visa.com: HTTPConnectionPool(host='music-game.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1DE910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://business.att.com: HTTPSConnectionPool(host='www.business.att.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://business.att.com: HTTPSConnectionPool(host='www.business.att.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://docker-local.build-agents.wbx2.com: HTTPConnectionPool(host='docker-local.build-agents.wbx2.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012169A97150>, 'Connection to docker-local.build-agents.wbx2.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://docker-local.build-agents.wbx2.com: HTTPConnectionPool(host='docker-local.build-agents.wbx2.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012169100B90>, 'Connection to docker-local.build-agents.wbx2.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://docker-local.build-agents.wbx2.com: HTTPConnectionPool(host='docker-local.build-agents.wbx2.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012169117DD0>, 'Connection to docker-local.build-agents.wbx2.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://docker-local.build-agents.wbx2.com: HTTPConnectionPool(host='docker-local.build-agents.wbx2.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012169117090>, 'Connection to docker-local.build-agents.wbx2.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://awesome-linux-software-cn.developer.visa.com: HTTPConnectionPool(host='awesome-linux-software-cn.developer.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A83750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://awesome-linux-software-cn.developer.visa.com: HTTPConnectionPool(host='awesome-linux-software-cn.developer.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A83750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://awesome-linux-software-cn.developer.visa.com: HTTPConnectionPool(host='awesome-linux-software-cn.developer.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A83750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://awesome-linux-software-cn.developer.visa.com: HTTPConnectionPool(host='awesome-linux-software-cn.developer.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A826D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://jewishhomelife-docs.ga/adobe/secure/document: HTTPConnectionPool(host='jewishhomelife-docs.ga', port=80): Max retries exceeded with url: /adobe/secure/document (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A81850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://jewishhomelife-docs.ga/adobe/secure/document: HTTPConnectionPool(host='jewishhomelife-docs.ga', port=80): Max retries exceeded with url: /adobe/secure/document (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A81850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://jewishhomelife-docs.ga/adobe/secure/document: HTTPConnectionPool(host='jewishhomelife-docs.ga', port=80): Max retries exceeded with url: /adobe/secure/document (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A81110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://jewishhomelife-docs.ga/adobe/secure/document: HTTPConnectionPool(host='jewishhomelife-docs.ga', port=80): Max retries exceeded with url: /adobe/secure/document (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A81110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bitrue.org: HTTPConnectionPool(host='bitrue.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A815D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bitrue.org: HTTPConnectionPool(host='bitrue.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A80810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bitrue.org: HTTPConnectionPool(host='bitrue.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A81D10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bitrue.org: HTTPConnectionPool(host='bitrue.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A82710>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://balley6.com/mazon/amazon: HTTPConnectionPool(host='balley6.com', port=80): Max retries exceeded with url: /mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A82B50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://balley6.com/mazon/amazon: HTTPConnectionPool(host='balley6.com', port=80): Max retries exceeded with url: /mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A82B50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://balley6.com/mazon/amazon: HTTPConnectionPool(host='balley6.com', port=80): Max retries exceeded with url: /mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A80D10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://balley6.com/mazon/amazon: HTTPConnectionPool(host='balley6.com', port=80): Max retries exceeded with url: /mazon/amazon (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169A829D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://allen-overy.emea.wxc-di.webex.com: HTTPConnectionPool(host='allen-overy.emea.wxc-di.webex.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216912AB10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://allen-overy.emea.wxc-di.webex.com: HTTPConnectionPool(host='allen-overy.emea.wxc-di.webex.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121691280D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://allen-overy.emea.wxc-di.webex.com: HTTPConnectionPool(host='allen-overy.emea.wxc-di.webex.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216912AB10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://allen-overy.emea.wxc-di.webex.com: HTTPConnectionPool(host='allen-overy.emea.wxc-di.webex.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169129210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nov-guest.com: HTTPConnectionPool(host='nov-guest.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169128490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nov-guest.com: HTTPConnectionPool(host='nov-guest.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216912A890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nov-guest.com: HTTPConnectionPool(host='nov-guest.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169128090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nov-guest.com: HTTPConnectionPool(host='nov-guest.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216912A750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www.attemplate.com/gbr/Login/SubmitPage/UU54dHVORnlpc2pmeVZIclloRzVDRlJqVzJYNjZQNWdUcEpkazhQWTdnSFJNbFJLclRqYXdDbkowYzJmY09LU285V0tyRzcxS0xzTjB0WExaTWhQWER6UTR1ZFkxMGwrb084OCs4QWh0emZqYktVM0lRVmNKYTdXYm1uanJGL3NjWFVNZjdOdmN2WEVNRDF0SmVpT0EyaUpTcFFUQTRjbTJZL3YzOGlqNlRjQmVyQ1RBdUJnSVFFYzdCQlFBK210aFNQdktRWGIyUnkxZUhFbFU1RmF2b0xaUTdoeERJdys0UWVyRUFsOGlhTTZDbVhleGZzL1NMSmhmN2ZtR0VmR3U4OUtmZjZTZHNrL0tBVml5Zm5RVTVjUy8zSWh2UGdaczJvSHpjU051YTd5TmVxTGVsM0hydFNLK1NndmRUWUJwTUZkem9UYzJLRkRocTMzbGlBbStlSnY3b08wMTJtQU9Nb3J5Y3RocTBmWS9IekFoMVEwYWxDUWMxZjlmVDdT: HTTPConnectionPool(host='www.attemplate.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.attemplate.com/gbr/Login/SubmitPage/UU54dHVORnlpc2pmeVZIclloRzVDRlJqVzJYNjZQNWdUcEpkazhQWTdnSFJNbFJLclRqYXdDbkowYzJmY09LU285V0tyRzcxS0xzTjB0WExaTWhQWER6UTR1ZFkxMGwrb084OCs4QWh0emZqYktVM0lRVmNKYTdXYm1uanJGL3NjWFVNZjdOdmN2WEVNRDF0SmVpT0EyaUpTcFFUQTRjbTJZL3YzOGlqNlRjQmVyQ1RBdUJnSVFFYzdCQlFBK210aFNQdktRWGIyUnkxZUhFbFU1RmF2b0xaUTdoeERJdys0UWVyRUFsOGlhTTZDbVhleGZzL1NMSmhmN2ZtR0VmR3U4OUtmZjZTZHNrL0tBVml5Zm5RVTVjUy8zSWh2UGdaczJvSHpjU051YTd5TmVxTGVsM0hydFNLK1NndmRUWUJwTUZkem9UYzJLRkRocTMzbGlBbStlSnY3b08wMTJtQU9Nb3J5Y3RocTBmWS9IekFoMVEwYWxDUWMxZjlmVDdT: HTTPConnectionPool(host='www.attemplate.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.attemplate.com/gbr/Login/SubmitPage/UU54dHVORnlpc2pmeVZIclloRzVDRlJqVzJYNjZQNWdUcEpkazhQWTdnSFJNbFJLclRqYXdDbkowYzJmY09LU285V0tyRzcxS0xzTjB0WExaTWhQWER6UTR1ZFkxMGwrb084OCs4QWh0emZqYktVM0lRVmNKYTdXYm1uanJGL3NjWFVNZjdOdmN2WEVNRDF0SmVpT0EyaUpTcFFUQTRjbTJZL3YzOGlqNlRjQmVyQ1RBdUJnSVFFYzdCQlFBK210aFNQdktRWGIyUnkxZUhFbFU1RmF2b0xaUTdoeERJdys0UWVyRUFsOGlhTTZDbVhleGZzL1NMSmhmN2ZtR0VmR3U4OUtmZjZTZHNrL0tBVml5Zm5RVTVjUy8zSWh2UGdaczJvSHpjU051YTd5TmVxTGVsM0hydFNLK1NndmRUWUJwTUZkem9UYzJLRkRocTMzbGlBbStlSnY3b08wMTJtQU9Nb3J5Y3RocTBmWS9IekFoMVEwYWxDUWMxZjlmVDdT: HTTPConnectionPool(host='www.attemplate.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://www.attemplate.com/gbr/Login/SubmitPage/UU54dHVORnlpc2pmeVZIclloRzVDRlJqVzJYNjZQNWdUcEpkazhQWTdnSFJNbFJLclRqYXdDbkowYzJmY09LU285V0tyRzcxS0xzTjB0WExaTWhQWER6UTR1ZFkxMGwrb084OCs4QWh0emZqYktVM0lRVmNKYTdXYm1uanJGL3NjWFVNZjdOdmN2WEVNRDF0SmVpT0EyaUpTcFFUQTRjbTJZL3YzOGlqNlRjQmVyQ1RBdUJnSVFFYzdCQlFBK210aFNQdktRWGIyUnkxZUhFbFU1RmF2b0xaUTdoeERJdys0UWVyRUFsOGlhTTZDbVhleGZzL1NMSmhmN2ZtR0VmR3U4OUtmZjZTZHNrL0tBVml5Zm5RVTVjUy8zSWh2UGdaczJvSHpjU051YTd5TmVxTGVsM0hydFNLK1NndmRUWUJwTUZkem9UYzJLRkRocTMzbGlBbStlSnY3b08wMTJtQU9Nb3J5Y3RocTBmWS9IekFoMVEwYWxDUWMxZjlmVDdT: HTTPConnectionPool(host='www.attemplate.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://hi-cooking.com/tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa: HTTPConnectionPool(host='hi-cooking.com', port=80): Max retries exceeded with url: /tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B305350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hi-cooking.com/tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa: HTTPConnectionPool(host='hi-cooking.com', port=80): Max retries exceeded with url: /tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169101DD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hi-cooking.com/tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa: HTTPConnectionPool(host='hi-cooking.com', port=80): Max retries exceeded with url: /tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169102310>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hi-cooking.com/tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa: HTTPConnectionPool(host='hi-cooking.com', port=80): Max retries exceeded with url: /tax/services.php?OTPVerification.aspx610fq9X4qDMw0JDtOR8SuwBomfk3a3r5XLMjOOBg1ItA3ZNISyvdq4drDHXv84NkyAuMdPaytGPaaT9loEAu0qeE0qo5qmluZzHI1H63HSIMT45Mcv1VDWUKf6O5oVmZoJai0pIwgVQo6rjFPxOXGuuvZIViEF0u25FkBZn4QUkCbvtKhSUa (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169100290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://dataprivacyoffice.com.br/wp-admin/network/update-core/standard2land/0zde1mjy=/password.php: HTTPConnectionPool(host='dataprivacyoffice.com.br', port=80): Max retries exceeded with url: /wp-admin/network/update-core/standard2land/0zde1mjy=/password.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216912BE90>, 'Connection to dataprivacyoffice.com.br timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://dataprivacyoffice.com.br/wp-admin/network/update-core/standard2land/0zde1mjy=/password.php: HTTPConnectionPool(host='dataprivacyoffice.com.br', port=80): Max retries exceeded with url: /wp-admin/network/update-core/standard2land/0zde1mjy=/password.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216FBF38D0>, 'Connection to dataprivacyoffice.com.br timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://dataprivacyoffice.com.br/wp-admin/network/update-core/standard2land/0zde1mjy=/password.php: HTTPConnectionPool(host='dataprivacyoffice.com.br', port=80): Max retries exceeded with url: /wp-admin/network/update-core/standard2land/0zde1mjy=/password.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121690E91D0>, 'Connection to dataprivacyoffice.com.br timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://dataprivacyoffice.com.br/wp-admin/network/update-core/standard2land/0zde1mjy=/password.php: HTTPConnectionPool(host='dataprivacyoffice.com.br', port=80): Max retries exceeded with url: /wp-admin/network/update-core/standard2land/0zde1mjy=/password.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B2F1FD0>, 'Connection to dataprivacyoffice.com.br timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://hedefbetcasino.com/SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php: HTTPConnectionPool(host='hedefbetcasino.com', port=80): Max retries exceeded with url: /SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121690E8410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hedefbetcasino.com/SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php: HTTPConnectionPool(host='hedefbetcasino.com', port=80): Max retries exceeded with url: /SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121690E8650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hedefbetcasino.com/SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php: HTTPConnectionPool(host='hedefbetcasino.com', port=80): Max retries exceeded with url: /SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121690E84D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hedefbetcasino.com/SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php: HTTPConnectionPool(host='hedefbetcasino.com', port=80): Max retries exceeded with url: /SaudiPost/box/4702e8b14be5454bd80067a76baf2158/zlatan.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121690EB190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://platino.bg/fonts/pNzg2NC0xMjkuNTYuODguMjI2LTY0p/_mlogMTE5Nzg0N0FCRENERkFNw6BB: HTTPConnectionPool(host='platino.bg', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://platino.bg/fonts/pNzg2NC0xMjkuNTYuODguMjI2LTY0p/_mlogMTE5Nzg0N0FCRENERkFNw6BB: HTTPConnectionPool(host='platino.bg', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://platino.bg/fonts/pNzg2NC0xMjkuNTYuODguMjI2LTY0p/_mlogMTE5Nzg0N0FCRENERkFNw6BB: HTTPConnectionPool(host='platino.bg', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://platino.bg/fonts/pNzg2NC0xMjkuNTYuODguMjI2LTY0p/_mlogMTE5Nzg0N0FCRENERkFNw6BB: HTTPConnectionPool(host='platino.bg', port=80): Read timed out. (read timeout=0.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://xn--banxo-caisse-pargne-nzb.fr/58bb61e68a0dd06: HTTPConnectionPool(host='xn--banxo-caisse-pargne-nzb.fr', port=80): Max retries exceeded with url: /58bb61e68a0dd06 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168736C10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://xn--banxo-caisse-pargne-nzb.fr/58bb61e68a0dd06: HTTPConnectionPool(host='xn--banxo-caisse-pargne-nzb.fr', port=80): Max retries exceeded with url: /58bb61e68a0dd06 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168734D10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://xn--banxo-caisse-pargne-nzb.fr/58bb61e68a0dd06: HTTPConnectionPool(host='xn--banxo-caisse-pargne-nzb.fr', port=80): Max retries exceeded with url: /58bb61e68a0dd06 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168736110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://xn--banxo-caisse-pargne-nzb.fr/58bb61e68a0dd06: HTTPConnectionPool(host='xn--banxo-caisse-pargne-nzb.fr', port=80): Max retries exceeded with url: /58bb61e68a0dd06 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168736490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coinmarket-account.cc/connect/reset: HTTPConnectionPool(host='coinmarket-account.cc', port=80): Max retries exceeded with url: /connect/reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168735790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coinmarket-account.cc/connect/reset: HTTPConnectionPool(host='coinmarket-account.cc', port=80): Max retries exceeded with url: /connect/reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687356D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coinmarket-account.cc/connect/reset: HTTPConnectionPool(host='coinmarket-account.cc', port=80): Max retries exceeded with url: /connect/reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687369D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://coinmarket-account.cc/connect/reset: HTTPConnectionPool(host='coinmarket-account.cc', port=80): Max retries exceeded with url: /connect/reset (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168734910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://hoponworld.com: HTTPSConnectionPool(host='hoponworld.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://hoponworld.com: HTTPSConnectionPool(host='hoponworld.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://hoponworld.com: HTTPSConnectionPool(host='hoponworld.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://hoponworld.com: HTTPSConnectionPool(host='hoponworld.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://secure.bhatphul.com/connect.html?timelimit=3D6bfb0876c04e31ff6f1=: HTTPConnectionPool(host='secure.bhatphul.com', port=80): Max retries exceeded with url: /connect.html?timelimit=3D6bfb0876c04e31ff6f1= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A56D50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.bhatphul.com/connect.html?timelimit=3D6bfb0876c04e31ff6f1=: HTTPConnectionPool(host='secure.bhatphul.com', port=80): Max retries exceeded with url: /connect.html?timelimit=3D6bfb0876c04e31ff6f1= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A55B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.bhatphul.com/connect.html?timelimit=3D6bfb0876c04e31ff6f1=: HTTPConnectionPool(host='secure.bhatphul.com', port=80): Max retries exceeded with url: /connect.html?timelimit=3D6bfb0876c04e31ff6f1= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A56A50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://secure.bhatphul.com/connect.html?timelimit=3D6bfb0876c04e31ff6f1=: HTTPConnectionPool(host='secure.bhatphul.com', port=80): Max retries exceeded with url: /connect.html?timelimit=3D6bfb0876c04e31ff6f1= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A56BD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://busy-mahavira.172-245-159-112.plesk.page/c21/5fade: HTTPConnectionPool(host='busy-mahavira.172-245-159-112.plesk.page', port=80): Max retries exceeded with url: /c21/5fade (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168961990>, 'Connection to busy-mahavira.172-245-159-112.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://busy-mahavira.172-245-159-112.plesk.page/c21/5fade: HTTPConnectionPool(host='busy-mahavira.172-245-159-112.plesk.page', port=80): Max retries exceeded with url: /c21/5fade (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168BC64D0>, 'Connection to busy-mahavira.172-245-159-112.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://busy-mahavira.172-245-159-112.plesk.page/c21/5fade: HTTPConnectionPool(host='busy-mahavira.172-245-159-112.plesk.page', port=80): Max retries exceeded with url: /c21/5fade (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168BC4190>, 'Connection to busy-mahavira.172-245-159-112.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://busy-mahavira.172-245-159-112.plesk.page/c21/5fade: HTTPConnectionPool(host='busy-mahavira.172-245-159-112.plesk.page', port=80): Max retries exceeded with url: /c21/5fade (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168268490>, 'Connection to busy-mahavira.172-245-159-112.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://janssencarepath.com: HTTPSConnectionPool(host='janssencarepath.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://janssencarepath.com: HTTPSConnectionPool(host='www.janssencarepath.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://janssencarepath.com: HTTPSConnectionPool(host='www.janssencarepath.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216814A090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168149D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168149FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/ncdsgo/bm9ybS5tZXJyaXR0QHF1YWxpdGVzdGdyb3VwLmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121681481D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dev.harznetzeisenbahn.info: HTTPConnectionPool(host='dev.harznetzeisenbahn.info', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168149010>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dev.harznetzeisenbahn.info: HTTPConnectionPool(host='dev.harznetzeisenbahn.info', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168148D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dev.harznetzeisenbahn.info: HTTPConnectionPool(host='dev.harznetzeisenbahn.info', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168149B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dev.harznetzeisenbahn.info: HTTPConnectionPool(host='dev.harznetzeisenbahn.info', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216814B190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://older-escaped.duckdns.org: HTTPConnectionPool(host='older-escaped.duckdns.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121754534D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://older-escaped.duckdns.org: HTTPConnectionPool(host='older-escaped.duckdns.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175452390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://older-escaped.duckdns.org: HTTPConnectionPool(host='older-escaped.duckdns.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121754531D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://older-escaped.duckdns.org: HTTPConnectionPool(host='older-escaped.duckdns.org', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175452AD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mehrcardvip.com/wp-includes/ID3/www.alibaba.com/alibaba: HTTPConnectionPool(host='mehrcardvip.com', port=80): Max retries exceeded with url: /wp-includes/ID3/www.alibaba.com/alibaba (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175451750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mehrcardvip.com/wp-includes/ID3/www.alibaba.com/alibaba: HTTPConnectionPool(host='mehrcardvip.com', port=80): Max retries exceeded with url: /wp-includes/ID3/www.alibaba.com/alibaba (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175452F90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mehrcardvip.com/wp-includes/ID3/www.alibaba.com/alibaba: HTTPConnectionPool(host='mehrcardvip.com', port=80): Max retries exceeded with url: /wp-includes/ID3/www.alibaba.com/alibaba (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175452910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mehrcardvip.com/wp-includes/ID3/www.alibaba.com/alibaba: HTTPConnectionPool(host='mehrcardvip.com', port=80): Max retries exceeded with url: /wp-includes/ID3/www.alibaba.com/alibaba (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175451F50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marcopaschacafe.com/public/bvtawygeca7sd4mfnfbjuzo9frqlbru2: HTTPConnectionPool(host='marcopaschacafe.com', port=80): Max retries exceeded with url: /public/bvtawygeca7sd4mfnfbjuzo9frqlbru2 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121754527D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marcopaschacafe.com/public/bvtawygeca7sd4mfnfbjuzo9frqlbru2: HTTPConnectionPool(host='marcopaschacafe.com', port=80): Max retries exceeded with url: /public/bvtawygeca7sd4mfnfbjuzo9frqlbru2 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175450F90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marcopaschacafe.com/public/bvtawygeca7sd4mfnfbjuzo9frqlbru2: HTTPConnectionPool(host='marcopaschacafe.com', port=80): Max retries exceeded with url: /public/bvtawygeca7sd4mfnfbjuzo9frqlbru2 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175450C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marcopaschacafe.com/public/bvtawygeca7sd4mfnfbjuzo9frqlbru2: HTTPConnectionPool(host='marcopaschacafe.com', port=80): Max retries exceeded with url: /public/bvtawygeca7sd4mfnfbjuzo9frqlbru2 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012175451310>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://monsterview.com: HTTPSConnectionPool(host='www.monster.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://sg.api.tgf123.com: HTTPConnectionPool(host='sg.api.tgf123.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215C7E4ED0>, 'Connection to sg.api.tgf123.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://sg.api.tgf123.com: HTTPConnectionPool(host='sg.api.tgf123.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215C7E6D50>, 'Connection to sg.api.tgf123.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://sg.api.tgf123.com: HTTPConnectionPool(host='sg.api.tgf123.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012193FF9D50>, 'Connection to sg.api.tgf123.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://sg.api.tgf123.com: HTTPConnectionPool(host='sg.api.tgf123.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012193FFA510>, 'Connection to sg.api.tgf123.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://tvzneghsiz.duckdns.org: HTTPConnectionPool(host='tvzneghsiz.duckdns.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001218E2E3410>, 'Connection to tvzneghsiz.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://tvzneghsiz.duckdns.org: HTTPConnectionPool(host='tvzneghsiz.duckdns.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012193FA4F90>, 'Connection to tvzneghsiz.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://tvzneghsiz.duckdns.org: HTTPConnectionPool(host='tvzneghsiz.duckdns.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121707942D0>, 'Connection to tvzneghsiz.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://tvzneghsiz.duckdns.org: HTTPConnectionPool(host='tvzneghsiz.duckdns.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012193FF85D0>, 'Connection to tvzneghsiz.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://kotlin.android.boilerplate.trusted.visa.com: HTTPConnectionPool(host='kotlin.android.boilerplate.trusted.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215C7C0090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://kotlin.android.boilerplate.trusted.visa.com: HTTPConnectionPool(host='kotlin.android.boilerplate.trusted.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012193FF9010>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://kotlin.android.boilerplate.trusted.visa.com: HTTPConnectionPool(host='kotlin.android.boilerplate.trusted.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215C7C02D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://kotlin.android.boilerplate.trusted.visa.com: HTTPConnectionPool(host='kotlin.android.boilerplate.trusted.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012193FF84D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://nathanmcguirelaw.com/09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542: HTTPConnectionPool(host='nathanmcguirelaw.com', port=80): Max retries exceeded with url: /09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D5910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nathanmcguirelaw.com/09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542: HTTPConnectionPool(host='nathanmcguirelaw.com', port=80): Max retries exceeded with url: /09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D5650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nathanmcguirelaw.com/09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542: HTTPConnectionPool(host='nathanmcguirelaw.com', port=80): Max retries exceeded with url: /09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D5150>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nathanmcguirelaw.com/09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542: HTTPConnectionPool(host='nathanmcguirelaw.com', port=80): Max retries exceeded with url: /09bb63ac0f2a1e960e9d60941e03fcb7/verify.php?country_x=-&acct_x=id-ppl=pa324162.158.63.222=scrpg=9971370eb8ecb024894f3d7782f11aec1d03a38e91527cfb4379f125e29efb92s=$1$u0xotjfc$k/ouhrtwv9.qsslqvo6p8/w38gecyjhkgitpudn9ux5afspldtre2lxvhmy4saf0ioqb6z71zjrcknmwvbqotnbe1lmgkqxrfvuyspv6zkd3ih2wiqm5eg7ocra8tyhb4jslnzjwfoc9ap0uxd3497525542 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D51D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://americas.hammondpowersolutions.com: HTTPSConnectionPool(host='americas.hammondpowersolutions.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://americas.hammondpowersolutions.com: HTTPSConnectionPool(host='americas.hammondpowersolutions.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://americas.hammondpowersolutions.com: HTTPSConnectionPool(host='americas.hammondpowersolutions.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://americas.hammondpowersolutions.com: HTTPSConnectionPool(host='americas.hammondpowersolutions.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://uswtowingllc.com/tuy: HTTPConnectionPool(host='uswtowingllc.com', port=80): Max retries exceeded with url: /tuy (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D4590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://uswtowingllc.com/tuy: HTTPConnectionPool(host='uswtowingllc.com', port=80): Max retries exceeded with url: /tuy (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D50D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://uswtowingllc.com/tuy: HTTPConnectionPool(host='uswtowingllc.com', port=80): Max retries exceeded with url: /tuy (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D5410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://uswtowingllc.com/tuy: HTTPConnectionPool(host='uswtowingllc.com', port=80): Max retries exceeded with url: /tuy (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215D0D7350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://peaceful-solomon.192-210-132-10.plesk.page/temisoft: HTTPConnectionPool(host='peaceful-solomon.192-210-132-10.plesk.page', port=80): Max retries exceeded with url: /temisoft (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215D0D65D0>, 'Connection to peaceful-solomon.192-210-132-10.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://peaceful-solomon.192-210-132-10.plesk.page/temisoft: HTTPConnectionPool(host='peaceful-solomon.192-210-132-10.plesk.page', port=80): Max retries exceeded with url: /temisoft (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012164091B90>, 'Connection to peaceful-solomon.192-210-132-10.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://peaceful-solomon.192-210-132-10.plesk.page/temisoft: HTTPConnectionPool(host='peaceful-solomon.192-210-132-10.plesk.page', port=80): Max retries exceeded with url: /temisoft (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001218BF4A290>, 'Connection to peaceful-solomon.192-210-132-10.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://peaceful-solomon.192-210-132-10.plesk.page/temisoft: HTTPConnectionPool(host='peaceful-solomon.192-210-132-10.plesk.page', port=80): Max retries exceeded with url: /temisoft (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215D0D7D10>, 'Connection to peaceful-solomon.192-210-132-10.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://atpflightschool.com: HTTPSConnectionPool(host='atpflightschool.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://atpflightschool.com: HTTPSConnectionPool(host='atpflightschool.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://atpflightschool.com: HTTPSConnectionPool(host='atpflightschool.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://atpflightschool.com: HTTPSConnectionPool(host='atpflightschool.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://hotmail-105482.square.site: HTTPSConnectionPool(host='hotmail-105482.square.site', port=443): Read timed out. (read timeout=0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://mtb.dns2.us/login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705: HTTPConnectionPool(host='mtb.dns2.us', port=80): Max retries exceeded with url: /login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001210A3D9E90>, 'Connection to mtb.dns2.us timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://mtb.dns2.us/login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705: HTTPConnectionPool(host='mtb.dns2.us', port=80): Max retries exceeded with url: /login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B910810>, 'Connection to mtb.dns2.us timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://mtb.dns2.us/login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705: HTTPConnectionPool(host='mtb.dns2.us', port=80): Max retries exceeded with url: /login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B912390>, 'Connection to mtb.dns2.us timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://mtb.dns2.us/login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705: HTTPConnectionPool(host='mtb.dns2.us', port=80): Max retries exceeded with url: /login/86eed61e3fd93082e3e47e5b1559c422/email.php?token=85168ba507495b931946c8afc3e8b55d7e79a7a1d797ba58d5d22ca7624ce0a2b4bcf040c2eb51112090f0a06e97e581bf249030e674be31ad27db0821878705 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B917890>, 'Connection to mtb.dns2.us timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://acikdenizdetronline.20-121-132-39.plesk.page: HTTPConnectionPool(host='acikdenizdetronline.20-121-132-39.plesk.page', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216F919ED0>, 'Connection to acikdenizdetronline.20-121-132-39.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://acikdenizdetronline.20-121-132-39.plesk.page: HTTPConnectionPool(host='acikdenizdetronline.20-121-132-39.plesk.page', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B912310>, 'Connection to acikdenizdetronline.20-121-132-39.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://acikdenizdetronline.20-121-132-39.plesk.page: HTTPConnectionPool(host='acikdenizdetronline.20-121-132-39.plesk.page', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B968390>, 'Connection to acikdenizdetronline.20-121-132-39.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://acikdenizdetronline.20-121-132-39.plesk.page: HTTPConnectionPool(host='acikdenizdetronline.20-121-132-39.plesk.page', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B96A050>, 'Connection to acikdenizdetronline.20-121-132-39.plesk.page timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://summitlearning.org: HTTPSConnectionPool(host='summitlearning.org', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://summitlearning.org: HTTPSConnectionPool(host='www.summitlearning.org', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://summitlearning.org: HTTPSConnectionPool(host='www.summitlearning.org', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://carsandbids.com: HTTPSConnectionPool(host='carsandbids.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://carsandbids.com: HTTPSConnectionPool(host='carsandbids.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://carsandbids.com: HTTPSConnectionPool(host='carsandbids.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://carsandbids.com: HTTPSConnectionPool(host='carsandbids.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://social56.toonblast.net: HTTPConnectionPool(host='social56.toonblast.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215CC1C590>, 'Connection to social56.toonblast.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://social56.toonblast.net: HTTPConnectionPool(host='social56.toonblast.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215CC1E150>, 'Connection to social56.toonblast.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://social56.toonblast.net: HTTPConnectionPool(host='social56.toonblast.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B9BDB50>, 'Connection to social56.toonblast.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://social56.toonblast.net: HTTPConnectionPool(host='social56.toonblast.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B9AF850>, 'Connection to social56.toonblast.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://m.mit.com.mx: HTTPConnectionPool(host='m.mit.com.mx', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B1AC990>, 'Connection to m.mit.com.mx timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://m.mit.com.mx: HTTPConnectionPool(host='m.mit.com.mx', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216E19A410>, 'Connection to m.mit.com.mx timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://m.mit.com.mx: HTTPConnectionPool(host='m.mit.com.mx', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B1BA550>, 'Connection to m.mit.com.mx timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://m.mit.com.mx: HTTPConnectionPool(host='m.mit.com.mx', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B1B88D0>, 'Connection to m.mit.com.mx timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://rakoten-account.rxjtag.ga: HTTPConnectionPool(host='rakoten-account.rxjtag.ga', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215CB6EF10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rakoten-account.rxjtag.ga: HTTPConnectionPool(host='rakoten-account.rxjtag.ga', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012105E3C2D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rakoten-account.rxjtag.ga: HTTPConnectionPool(host='rakoten-account.rxjtag.ga', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E1634D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rakoten-account.rxjtag.ga: HTTPConnectionPool(host='rakoten-account.rxjtag.ga', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E162310>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://marketing.jffalcom.com.br/DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b: HTTPConnectionPool(host='marketing.jffalcom.com.br', port=80): Max retries exceeded with url: /DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BBD90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marketing.jffalcom.com.br/DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b: HTTPConnectionPool(host='marketing.jffalcom.com.br', port=80): Max retries exceeded with url: /DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B9ED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marketing.jffalcom.com.br/DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b: HTTPConnectionPool(host='marketing.jffalcom.com.br', port=80): Max retries exceeded with url: /DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BB190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://marketing.jffalcom.com.br/DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b: HTTPConnectionPool(host='marketing.jffalcom.com.br', port=80): Max retries exceeded with url: /DHL/dhl/dhl/dhl/59b18ff76e025c22ccf6d8333facb07b (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BAB90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www-becuconnecton.serveftp.com/ind/BECU/login.php: HTTPConnectionPool(host='www-becuconnecton.serveftp.com', port=80): Max retries exceeded with url: /ind/BECU/login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BBA90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www-becuconnecton.serveftp.com/ind/BECU/login.php: HTTPConnectionPool(host='www-becuconnecton.serveftp.com', port=80): Max retries exceeded with url: /ind/BECU/login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BA510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www-becuconnecton.serveftp.com/ind/BECU/login.php: HTTPConnectionPool(host='www-becuconnecton.serveftp.com', port=80): Max retries exceeded with url: /ind/BECU/login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B8BD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://www-becuconnecton.serveftp.com/ind/BECU/login.php: HTTPConnectionPool(host='www-becuconnecton.serveftp.com', port=80): Max retries exceeded with url: /ind/BECU/login.php (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BBB90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://api.marketing.englishlive.ef.com: HTTPConnectionPool(host='api.marketing.englishlive.ef.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BB910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://api.marketing.englishlive.ef.com: HTTPConnectionPool(host='api.marketing.englishlive.ef.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1AE7D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://api.marketing.englishlive.ef.com: HTTPConnectionPool(host='api.marketing.englishlive.ef.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B92D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://api.marketing.englishlive.ef.com: HTTPConnectionPool(host='api.marketing.englishlive.ef.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1AC4D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://bizniz.app/pikllee/8ehvr8bkzp4f273jkc7cowap.php?secure&share=0iHAA01645648522f27ab6effccaeb600c40e277933b3622f27ab6effccaeb600c40e277933b3622f27ab6effccaeb600c40e277933b3622f27ab6effccaeb600c40e277933b3622f27ab6effccaeb600c40e277933b3622: HTTPSConnectionPool(host='bizniz.app', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://nocontent-ygxksnxr.velocityhub.com/nextVRF.html?location=33f5b8f06951403124e59910c8ff3885: HTTPConnectionPool(host='nocontent-ygxksnxr.velocityhub.com', port=80): Max retries exceeded with url: /nextVRF.html?location=33f5b8f06951403124e59910c8ff3885 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1BA510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nocontent-ygxksnxr.velocityhub.com/nextVRF.html?location=33f5b8f06951403124e59910c8ff3885: HTTPConnectionPool(host='nocontent-ygxksnxr.velocityhub.com', port=80): Max retries exceeded with url: /nextVRF.html?location=33f5b8f06951403124e59910c8ff3885 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E122E50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nocontent-ygxksnxr.velocityhub.com/nextVRF.html?location=33f5b8f06951403124e59910c8ff3885: HTTPConnectionPool(host='nocontent-ygxksnxr.velocityhub.com', port=80): Max retries exceeded with url: /nextVRF.html?location=33f5b8f06951403124e59910c8ff3885 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B88D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://nocontent-ygxksnxr.velocityhub.com/nextVRF.html?location=33f5b8f06951403124e59910c8ff3885: HTTPConnectionPool(host='nocontent-ygxksnxr.velocityhub.com', port=80): Max retries exceeded with url: /nextVRF.html?location=33f5b8f06951403124e59910c8ff3885 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E121E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rebel.xion.oxcs.net: HTTPConnectionPool(host='rebel.xion.oxcs.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B9CD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rebel.xion.oxcs.net: HTTPConnectionPool(host='rebel.xion.oxcs.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E1228D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rebel.xion.oxcs.net: HTTPConnectionPool(host='rebel.xion.oxcs.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B1B8910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://rebel.xion.oxcs.net: HTTPConnectionPool(host='rebel.xion.oxcs.net', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216E122590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://pochtarefund-xeq0sd.aakkl.xyz/app: HTTPConnectionPool(host='pochtarefund-xeq0sd.aakkl.xyz', port=80): Max retries exceeded with url: /app (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B101A10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://pochtarefund-xeq0sd.aakkl.xyz/app: HTTPConnectionPool(host='pochtarefund-xeq0sd.aakkl.xyz', port=80): Max retries exceeded with url: /app (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B103090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://pochtarefund-xeq0sd.aakkl.xyz/app: HTTPConnectionPool(host='pochtarefund-xeq0sd.aakkl.xyz', port=80): Max retries exceeded with url: /app (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B103950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://pochtarefund-xeq0sd.aakkl.xyz/app: HTTPConnectionPool(host='pochtarefund-xeq0sd.aakkl.xyz', port=80): Max retries exceeded with url: /app (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B100C10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://betaal-wijze.nl/knab: HTTPConnectionPool(host='betaal-wijze.nl', port=80): Max retries exceeded with url: /knab (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B7B9290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betaal-wijze.nl/knab: HTTPConnectionPool(host='betaal-wijze.nl', port=80): Max retries exceeded with url: /knab (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B7B92D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betaal-wijze.nl/knab: HTTPConnectionPool(host='betaal-wijze.nl', port=80): Max retries exceeded with url: /knab (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B7B8F10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://betaal-wijze.nl/knab: HTTPConnectionPool(host='betaal-wijze.nl', port=80): Max retries exceeded with url: /knab (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B7B87D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://view.genial.ly/60f6e5b47e8cfc0d72d973a7/interactive-content-genially: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://view.genial.ly/60f6e5b47e8cfc0d72d973a7/interactive-content-genially: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://view.genial.ly/60f6e5b47e8cfc0d72d973a7/interactive-content-genially: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://view.genial.ly/60f6e5b47e8cfc0d72d973a7/interactive-content-genially: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://it-aruba.site/fatturazione/v2e513: HTTPConnectionPool(host='it-aruba.site', port=80): Max retries exceeded with url: /fatturazione/v2e513 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168841390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://it-aruba.site/fatturazione/v2e513: HTTPConnectionPool(host='it-aruba.site', port=80): Max retries exceeded with url: /fatturazione/v2e513 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168840090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://it-aruba.site/fatturazione/v2e513: HTTPConnectionPool(host='it-aruba.site', port=80): Max retries exceeded with url: /fatturazione/v2e513 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121688401D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://it-aruba.site/fatturazione/v2e513: HTTPConnectionPool(host='it-aruba.site', port=80): Max retries exceeded with url: /fatturazione/v2e513 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168841C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://video1080plus.blogspot.com.co: HTTPConnectionPool(host='video1080plus.blogspot.com.co', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://video1080plus.blogspot.com.co: HTTPConnectionPool(host='video1080plus.blogspot.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://video1080plus.blogspot.com.co: HTTPConnectionPool(host='video1080plus.blogspot.com.co', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://video1080plus.blogspot.com.co: HTTPSConnectionPool(host='video1080plus.blogspot.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://drillerservices.com: HTTPConnectionPool(host='drillerservices.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B4C2810>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://drillerservices.com: HTTPConnectionPool(host='drillerservices.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216F79BCD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://drillerservices.com: HTTPConnectionPool(host='drillerservices.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687EB090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://drillerservices.com: HTTPConnectionPool(host='drillerservices.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215CC5FD50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://chelonian-clang.000webhostapp.com/cox.full/cox.full/Zo/stepCoxMail/log/sycho/index.html: HTTPConnectionPool(host='chelonian-clang.000webhostapp.com', port=80): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://cheaplocksmitharlingtonva.com/tech/onedrive-RD38/onedrive-RD38: HTTPSConnectionPool(host='cheaplocksmitharlingtonva.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://cheaplocksmitharlingtonva.com/tech/onedrive-RD38/onedrive-RD38: HTTPSConnectionPool(host='cheaplocksmitharlingtonva.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://cheaplocksmitharlingtonva.com/tech/onedrive-RD38/onedrive-RD38: HTTPSConnectionPool(host='cheaplocksmitharlingtonva.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://cheaplocksmitharlingtonva.com/tech/onedrive-RD38/onedrive-RD38: HTTPSConnectionPool(host='cheaplocksmitharlingtonva.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://metamaskcoin.diskstation.eu: HTTPConnectionPool(host='metamaskcoin.diskstation.eu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121708AB910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://metamaskcoin.diskstation.eu: HTTPConnectionPool(host='metamaskcoin.diskstation.eu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687EB850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://metamaskcoin.diskstation.eu: HTTPConnectionPool(host='metamaskcoin.diskstation.eu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215CC5C150>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://metamaskcoin.diskstation.eu: HTTPConnectionPool(host='metamaskcoin.diskstation.eu', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687EAD50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://steamcommunityliv.top: HTTPConnectionPool(host='steamcommunityliv.top', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B10FCD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://steamcommunityliv.top: HTTPConnectionPool(host='steamcommunityliv.top', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215CC5D450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://steamcommunityliv.top: HTTPConnectionPool(host='steamcommunityliv.top', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000121687EBE50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://steamcommunityliv.top: HTTPConnectionPool(host='steamcommunityliv.top', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B10FB50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://dkds8srdioygieonmq6zsc.qwo231sdx.club/index/usps/index.html: HTTPConnectionPool(host='dkds8srdioygieonmq6zsc.qwo231sdx.club', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A87210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dkds8srdioygieonmq6zsc.qwo231sdx.club/index/usps/index.html: HTTPConnectionPool(host='dkds8srdioygieonmq6zsc.qwo231sdx.club', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A87550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dkds8srdioygieonmq6zsc.qwo231sdx.club/index/usps/index.html: HTTPConnectionPool(host='dkds8srdioygieonmq6zsc.qwo231sdx.club', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A87290>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://dkds8srdioygieonmq6zsc.qwo231sdx.club/index/usps/index.html: HTTPConnectionPool(host='dkds8srdioygieonmq6zsc.qwo231sdx.club', port=80): Max retries exceeded with url: /index/usps/index.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A87890>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://joeyr.ml/chase/chasefil: HTTPConnectionPool(host='joeyr.ml', port=80): Max retries exceeded with url: /chase/chasefil (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACE790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://joeyr.ml/chase/chasefil: HTTPConnectionPool(host='joeyr.ml', port=80): Max retries exceeded with url: /chase/chasefil (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACE0D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://joeyr.ml/chase/chasefil: HTTPConnectionPool(host='joeyr.ml', port=80): Max retries exceeded with url: /chase/chasefil (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACEA10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://joeyr.ml/chase/chasefil: HTTPConnectionPool(host='joeyr.ml', port=80): Max retries exceeded with url: /chase/chasefil (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ADB2D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://json.graphql.server.spendclarity.visa.com: HTTPConnectionPool(host='json.graphql.server.spendclarity.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACE910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://json.graphql.server.spendclarity.visa.com: HTTPConnectionPool(host='json.graphql.server.spendclarity.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACCED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://json.graphql.server.spendclarity.visa.com: HTTPConnectionPool(host='json.graphql.server.spendclarity.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACE6D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://json.graphql.server.spendclarity.visa.com: HTTPConnectionPool(host='json.graphql.server.spendclarity.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACDE50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168ACE3D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AAF350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AAF210>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://infoforubd.com/email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ==: HTTPConnectionPool(host='infoforubd.com', port=80): Max retries exceeded with url: /email/verification/3frsq8/aGVsbG9AYmVuY2htYXJrMzY1LmNvbQ== (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AAF090>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://privateinternetaccess.com: HTTPSConnectionPool(host='www.privateinternetaccess.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://privateinternetaccess.com: HTTPSConnectionPool(host='www.privateinternetaccess.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://privateinternetaccess.com: HTTPSConnectionPool(host='www.privateinternetaccess.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://privateinternetaccess.com: HTTPSConnectionPool(host='www.privateinternetaccess.com', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://neflxiam0967authed.duckdns.org/v5/update.php: HTTPConnectionPool(host='neflxiam0967authed.duckdns.org', port=80): Max retries exceeded with url: /v5/update.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B44B250>, 'Connection to neflxiam0967authed.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://neflxiam0967authed.duckdns.org/v5/update.php: HTTPConnectionPool(host='neflxiam0967authed.duckdns.org', port=80): Max retries exceeded with url: /v5/update.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168ACC790>, 'Connection to neflxiam0967authed.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://neflxiam0967authed.duckdns.org/v5/update.php: HTTPConnectionPool(host='neflxiam0967authed.duckdns.org', port=80): Max retries exceeded with url: /v5/update.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168ACE410>, 'Connection to neflxiam0967authed.duckdns.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://neflxiam0967authed.duckdns.org/v5/update.php: HTTPConnectionPool(host='neflxiam0967authed.duckdns.org', port=80): Max retries exceeded with url: /v5/update.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AAD7D0>, 'Connection to neflxiam0967authed.duckdns.org timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://share-field-7570.yralecaeaghnrsn.workers.dev/99ec8f90-8267-49a3-82bb-a9ca2a44854d: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://share-field-7570.yralecaeaghnrsn.workers.dev/99ec8f90-8267-49a3-82bb-a9ca2a44854d: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://share-field-7570.yralecaeaghnrsn.workers.dev/99ec8f90-8267-49a3-82bb-a9ca2a44854d: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://share-field-7570.yralecaeaghnrsn.workers.dev/99ec8f90-8267-49a3-82bb-a9ca2a44854d: object of type 'NoneType' has no len()\n",
      "Error fetching or parsing URL http://aep.devonway.com: HTTPConnectionPool(host='aep.devonway.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168ABF1D0>, 'Connection to aep.devonway.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://aep.devonway.com: HTTPConnectionPool(host='aep.devonway.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B101B10>, 'Connection to aep.devonway.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://aep.devonway.com: HTTPConnectionPool(host='aep.devonway.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AAD050>, 'Connection to aep.devonway.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://aep.devonway.com: HTTPConnectionPool(host='aep.devonway.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AAFC10>, 'Connection to aep.devonway.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://leahstravelist.com/son/so/sf_rand_string_lowercase6/Y2FtYmlvLmluZm9ybWFAYzZiYW5rLmNvbQ==: HTTPConnectionPool(host='leahstravelist.com', port=80): Max retries exceeded with url: /son/so/sf_rand_string_lowercase6/Y2FtYmlvLmluZm9ybWFAYzZiYW5rLmNvbQ== (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168B07810>, 'Connection to leahstravelist.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://pyrevitlabs.notion.site: HTTPSConnectionPool(host='pyrevitlabs.notion.site', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://inputs15.georgetown.splunkcloud.com: HTTPConnectionPool(host='inputs15.georgetown.splunkcloud.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AF0F50>, 'Connection to inputs15.georgetown.splunkcloud.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://inputs15.georgetown.splunkcloud.com: HTTPConnectionPool(host='inputs15.georgetown.splunkcloud.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AF2B50>, 'Connection to inputs15.georgetown.splunkcloud.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://inputs15.georgetown.splunkcloud.com: HTTPConnectionPool(host='inputs15.georgetown.splunkcloud.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168A30690>, 'Connection to inputs15.georgetown.splunkcloud.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://inputs15.georgetown.splunkcloud.com: HTTPConnectionPool(host='inputs15.georgetown.splunkcloud.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AF2090>, 'Connection to inputs15.georgetown.splunkcloud.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://paypalonlineverificationpage.babycarehospital.com/ztt: HTTPConnectionPool(host='paypalonlineverificationpage.babycarehospital.com', port=80): Max retries exceeded with url: /ztt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AF0310>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://paypalonlineverificationpage.babycarehospital.com/ztt: HTTPConnectionPool(host='paypalonlineverificationpage.babycarehospital.com', port=80): Max retries exceeded with url: /ztt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AF0C50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://paypalonlineverificationpage.babycarehospital.com/ztt: HTTPConnectionPool(host='paypalonlineverificationpage.babycarehospital.com', port=80): Max retries exceeded with url: /ztt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AF01D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://paypalonlineverificationpage.babycarehospital.com/ztt: HTTPConnectionPool(host='paypalonlineverificationpage.babycarehospital.com', port=80): Max retries exceeded with url: /ztt (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AF0150>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://planfront.net: HTTPConnectionPool(host='planfront.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AF2A90>, 'Connection to planfront.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://planfront.net: HTTPConnectionPool(host='planfront.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168A46810>, 'Connection to planfront.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://planfront.net: HTTPConnectionPool(host='planfront.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168ACDD90>, 'Connection to planfront.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://planfront.net: HTTPConnectionPool(host='planfront.net', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168A84750>, 'Connection to planfront.net timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://shipmenthepl.com: HTTPConnectionPool(host='shipmenthepl.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A328D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://shipmenthepl.com: HTTPConnectionPool(host='shipmenthepl.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AAC4D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://shipmenthepl.com: HTTPConnectionPool(host='shipmenthepl.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A85ED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://shipmenthepl.com: HTTPConnectionPool(host='shipmenthepl.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AAC110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://87bde12c.dr.youme.im: HTTPConnectionPool(host='87bde12c.dr.youme.im', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168A85090>, 'Connection to 87bde12c.dr.youme.im timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://87bde12c.dr.youme.im: HTTPConnectionPool(host='87bde12c.dr.youme.im', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216888FAD0>, 'Connection to 87bde12c.dr.youme.im timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://87bde12c.dr.youme.im: HTTPConnectionPool(host='87bde12c.dr.youme.im', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168A44610>, 'Connection to 87bde12c.dr.youme.im timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://87bde12c.dr.youme.im: HTTPConnectionPool(host='87bde12c.dr.youme.im', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012168AF0DD0>, 'Connection to 87bde12c.dr.youme.im timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://vovaer.com: HTTPConnectionPool(host='vovaer.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A31590>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://vovaer.com: HTTPConnectionPool(host='vovaer.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A31650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://vovaer.com: HTTPConnectionPool(host='vovaer.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A31790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://vovaer.com: HTTPConnectionPool(host='vovaer.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168A31510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://spotlight.auth.visa.com: HTTPConnectionPool(host='spotlight.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001215CD08DD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://spotlight.auth.visa.com: HTTPConnectionPool(host='spotlight.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B652790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://spotlight.auth.visa.com: HTTPConnectionPool(host='spotlight.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B652CD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://spotlight.auth.visa.com: HTTPConnectionPool(host='spotlight.auth.visa.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B652C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mail.fionap.tk: HTTPConnectionPool(host='mail.fionap.tk', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6D0190>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mail.fionap.tk: HTTPConnectionPool(host='mail.fionap.tk', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B691E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mail.fionap.tk: HTTPConnectionPool(host='mail.fionap.tk', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6D2550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://mail.fionap.tk: HTTPConnectionPool(host='mail.fionap.tk', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B691E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://440000000087952346598756429.tk/checkpoint_next.html: HTTPConnectionPool(host='440000000087952346598756429.tk', port=80): Max retries exceeded with url: /checkpoint_next.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6D1F50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://440000000087952346598756429.tk/checkpoint_next.html: HTTPConnectionPool(host='440000000087952346598756429.tk', port=80): Max retries exceeded with url: /checkpoint_next.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B692310>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://440000000087952346598756429.tk/checkpoint_next.html: HTTPConnectionPool(host='440000000087952346598756429.tk', port=80): Max retries exceeded with url: /checkpoint_next.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6919D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://440000000087952346598756429.tk/checkpoint_next.html: HTTPConnectionPool(host='440000000087952346598756429.tk', port=80): Max retries exceeded with url: /checkpoint_next.html (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B691FD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://1auth-easytweb.com: HTTPConnectionPool(host='1auth-easytweb.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6745D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://1auth-easytweb.com: HTTPConnectionPool(host='1auth-easytweb.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B674B10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://1auth-easytweb.com: HTTPConnectionPool(host='1auth-easytweb.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B675A50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://1auth-easytweb.com: HTTPConnectionPool(host='1auth-easytweb.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B676D10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://api.electricitymap.org: HTTPSConnectionPool(host='api-eu.electricitymap.org', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com: HTTPConnectionPool(host='apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B653750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com: HTTPConnectionPool(host='apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6515D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com: HTTPConnectionPool(host='apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216B6515D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com: HTTPConnectionPool(host='apps.fireeye.com.sigenv1.qq.p1.sin.opendns.com', port=80): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012168AFBA90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://194.195.86.192/sh/CA72u10/mbmo/continue.php: HTTPConnectionPool(host='194.195.86.192', port=80): Max retries exceeded with url: /sh/CA72u10/mbmo/continue.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B651DD0>, 'Connection to 194.195.86.192 timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://194.195.86.192/sh/CA72u10/mbmo/continue.php: HTTPConnectionPool(host='194.195.86.192', port=80): Max retries exceeded with url: /sh/CA72u10/mbmo/continue.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698BC290>, 'Connection to 194.195.86.192 timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://194.195.86.192/sh/CA72u10/mbmo/continue.php: HTTPConnectionPool(host='194.195.86.192', port=80): Max retries exceeded with url: /sh/CA72u10/mbmo/continue.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698CF210>, 'Connection to 194.195.86.192 timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://194.195.86.192/sh/CA72u10/mbmo/continue.php: HTTPConnectionPool(host='194.195.86.192', port=80): Max retries exceeded with url: /sh/CA72u10/mbmo/continue.php (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B605950>, 'Connection to 194.195.86.192 timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://bg3nat4.larian.com: HTTPConnectionPool(host='bg3nat4.larian.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698BE390>, 'Connection to bg3nat4.larian.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://bg3nat4.larian.com: HTTPConnectionPool(host='bg3nat4.larian.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698C4090>, 'Connection to bg3nat4.larian.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://bg3nat4.larian.com: HTTPConnectionPool(host='bg3nat4.larian.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698C5C90>, 'Connection to bg3nat4.larian.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://bg3nat4.larian.com: HTTPConnectionPool(host='bg3nat4.larian.com', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698C7850>, 'Connection to bg3nat4.larian.com timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://omergunes.net/ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12: HTTPConnectionPool(host='omergunes.net', port=80): Max retries exceeded with url: /ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216990ADD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://omergunes.net/ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12: HTTPConnectionPool(host='omergunes.net', port=80): Max retries exceeded with url: /ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216990B3D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://omergunes.net/ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12: HTTPConnectionPool(host='omergunes.net', port=80): Max retries exceeded with url: /ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001216990A410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://omergunes.net/ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12: HTTPConnectionPool(host='omergunes.net', port=80): Max retries exceeded with url: /ayaz/wp-content/uploads/revslider/travel/slides/%20img%20/%20directory%20/%20plan%20/omergunes/91138c608ccd3e59251ca81ffd951b0c/informations/login.php?cmd=login_submit&id=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12&session=8da7ef7bcf36ba870474e1a2d7fefa128da7ef7bcf36ba870474e1a2d7fefa12 (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000012169909850>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "Error fetching or parsing URL http://fallback.axc.eu: HTTPConnectionPool(host='fallback.axc.eu', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121699099D0>, 'Connection to fallback.axc.eu timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://fallback.axc.eu: HTTPConnectionPool(host='fallback.axc.eu', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216989A3D0>, 'Connection to fallback.axc.eu timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://fallback.axc.eu: HTTPConnectionPool(host='fallback.axc.eu', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x00000121698982D0>, 'Connection to fallback.axc.eu timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://fallback.axc.eu: HTTPConnectionPool(host='fallback.axc.eu', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x0000012169899950>, 'Connection to fallback.axc.eu timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://ns-1207.awsdns-22.org: HTTPConnectionPool(host='ns-1207.awsdns-22.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001216B651A10>, 'Connection to ns-1207.awsdns-22.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://ns-1207.awsdns-22.org: HTTPConnectionPool(host='ns-1207.awsdns-22.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215CD4FE10>, 'Connection to ns-1207.awsdns-22.org timed out. (connect timeout=0.5)'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching or parsing URL http://ns-1207.awsdns-22.org: HTTPConnectionPool(host='ns-1207.awsdns-22.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215CD4EC90>, 'Connection to ns-1207.awsdns-22.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://ns-1207.awsdns-22.org: HTTPConnectionPool(host='ns-1207.awsdns-22.org', port=80): Max retries exceeded with url: / (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0x000001215CCA8D10>, 'Connection to ns-1207.awsdns-22.org timed out. (connect timeout=0.5)'))\n",
      "Error fetching or parsing URL http://orvis-us.attn.tv: HTTPSConnectionPool(host='orvis-us.attn.tv', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://orvis-us.attn.tv: HTTPSConnectionPool(host='orvis-us.attn.tv', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://orvis-us.attn.tv: HTTPSConnectionPool(host='orvis-us.attn.tv', port=443): Read timed out. (read timeout=0.5)\n",
      "Error fetching or parsing URL http://orvis-us.attn.tv: HTTPSConnectionPool(host='orvis-us.attn.tv', port=443): Read timed out. (read timeout=0.5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 225\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Apply feature extraction\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m features \u001b[38;5;241m=\u001b[39m balanced_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries({\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_url_length(x),\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_dot_count(x),\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyphen_count_domain\u001b[39m\u001b[38;5;124m'\u001b[39m: get_hyphen_count_in_domain(x),\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecurity_sensitive_words\u001b[39m\u001b[38;5;124m'\u001b[39m: contains_security_sensitive_words(x),\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirectory_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_directory_length(x),\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_directory_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_sub_directory_count(x),\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_count_path\u001b[39m\u001b[38;5;124m'\u001b[39m: get_token_count_in_path(x),\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlargest_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_largest_token_length(x),\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_average_token_length(x),\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_file_length(x),\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_ip\u001b[39m\u001b[38;5;124m'\u001b[39m: contains_ip(x),\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot_count_in_file\u001b[39m\u001b[38;5;124m'\u001b[39m: get_dot_count_in_file(x),\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelimiter_count_in_file\u001b[39m\u001b[38;5;124m'\u001b[39m: get_delimiter_count_in_file(x),\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_arguments_length(x),\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_arguments\u001b[39m\u001b[38;5;124m'\u001b[39m: get_number_of_arguments(x),\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_of_largest_argument_value\u001b[39m\u001b[38;5;124m'\u001b[39m: get_length_of_largest_argument_value(x),\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_delimiters_in_arguments\u001b[39m\u001b[38;5;124m'\u001b[39m: get_max_delimiters_in_arguments(x),\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecial_character_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_special_character_count(x),\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m: get_entropy(x),\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_shortened\u001b[39m\u001b[38;5;124m'\u001b[39m: check_url_shortened(x),\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubdomain_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_subdomain_count(x),\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuspicious_tld\u001b[39m\u001b[38;5;124m'\u001b[39m: get_suspicious_tld(x),\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: get_numeric_ratio(x),\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_token_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlargest_domain_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_domain_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_images\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_links\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_title_length\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_paragraphs\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_word_count(x)\n\u001b[0;32m    258\u001b[0m }))\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Concatenate original DF with features\u001b[39;00m\n\u001b[0;32m    262\u001b[0m balanced_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([balanced_df, features], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[21], line 253\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(words)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Apply feature extraction\u001b[39;00m\n\u001b[0;32m    225\u001b[0m features \u001b[38;5;241m=\u001b[39m balanced_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURL\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries({\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_url_length(x),\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_dot_count(x),\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyphen_count_domain\u001b[39m\u001b[38;5;124m'\u001b[39m: get_hyphen_count_in_domain(x),\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msecurity_sensitive_words\u001b[39m\u001b[38;5;124m'\u001b[39m: contains_security_sensitive_words(x),\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdirectory_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_directory_length(x),\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msub_directory_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_sub_directory_count(x),\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_count_path\u001b[39m\u001b[38;5;124m'\u001b[39m: get_token_count_in_path(x),\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlargest_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_largest_token_length(x),\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_average_token_length(x),\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_file_length(x),\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontains_ip\u001b[39m\u001b[38;5;124m'\u001b[39m: contains_ip(x),\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot_count_in_file\u001b[39m\u001b[38;5;124m'\u001b[39m: get_dot_count_in_file(x),\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelimiter_count_in_file\u001b[39m\u001b[38;5;124m'\u001b[39m: get_delimiter_count_in_file(x),\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marguments_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_arguments_length(x),\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber_of_arguments\u001b[39m\u001b[38;5;124m'\u001b[39m: get_number_of_arguments(x),\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlength_of_largest_argument_value\u001b[39m\u001b[38;5;124m'\u001b[39m: get_length_of_largest_argument_value(x),\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_delimiters_in_arguments\u001b[39m\u001b[38;5;124m'\u001b[39m: get_max_delimiters_in_arguments(x),\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecial_character_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_special_character_count(x),\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m: get_entropy(x),\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl_shortened\u001b[39m\u001b[38;5;124m'\u001b[39m: check_url_shortened(x),\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubdomain_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_subdomain_count(x),\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuspicious_tld\u001b[39m\u001b[38;5;124m'\u001b[39m: get_suspicious_tld(x),\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m: get_numeric_ratio(x),\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain_token_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlargest_domain_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_domain_token_length\u001b[39m\u001b[38;5;124m'\u001b[39m: get_domain_features(x)[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_images\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_links\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_title_length\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_paragraphs\u001b[39m\u001b[38;5;124m'\u001b[39m: fetch_and_parse(x)[\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m'\u001b[39m: get_word_count(x)\n\u001b[0;32m    258\u001b[0m }))\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m# Concatenate original DF with features\u001b[39;00m\n\u001b[0;32m    262\u001b[0m balanced_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([balanced_df, features], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 27\u001b[0m, in \u001b[0;36mfetch_and_parse\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     24\u001b[0m url \u001b[38;5;241m=\u001b[39m ensure_scheme(url)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Fetch the content of the URL\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     28\u001b[0m html_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Parse the HTML content\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:415\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    413\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest_chunked(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 415\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser-agent\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (six\u001b[38;5;241m.\u001b[39mensure_str(k\u001b[38;5;241m.\u001b[39mlower()) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m headers):\n\u001b[0;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28msuper\u001b[39m(HTTPConnection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headers\u001b[38;5;241m=\u001b[39m{}, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   1284\u001b[0m             encode_chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1332\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1039\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m \n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1047\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msocket_options\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     84\u001b[0m         sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m     sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sock\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import tldextract \n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "\n",
    "\n",
    "def ensure_scheme(url):\n",
    "    if not urlparse(url).scheme:\n",
    "        url = 'http://' + url\n",
    "    return url\n",
    "\n",
    "# Feature extraction functions\n",
    "def get_url_length(url):\n",
    "    return len(url)\n",
    "\n",
    "def get_dot_count(url):\n",
    "    return url.count('.')\n",
    "\n",
    "def contains_security_sensitive_words(url):\n",
    "    security_sensitive_words = [\n",
    "    'login', 'password', 'admin', 'root', 'secret', 'private', 'secure', 'confidential', \n",
    "    'bank', 'creditcard', 'account', 'authentication', 'authorization', 'session', 'token', \n",
    "    'apikey', 'ssl', 'https', 'secure', 'encrypted', 'auth', 'signin', 'signup', 'verification', \n",
    "    'resetpassword', 'change-password', 'forgot-password', 'otp', '2fa', 'phishing', 'malware', \n",
    "    'virus', 'trojan', 'exploit', 'hacker', 'attack', 'security', 'vulnerable', 'injection', \n",
    "    'xss', 'csrf', 'dos', 'ddos', 'bruteforce', 'firewall', 'vpn', 'proxy', 'tor', 'security-question', \n",
    "    'privacy-policy'\n",
    "]\n",
    "\n",
    "    return int(any(word in url for word in security_sensitive_words))\n",
    "\n",
    "def get_directory_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    return len(path)\n",
    "\n",
    "def get_sub_directory_count(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    return path.count('/') - 1\n",
    "\n",
    "def get_token_count_in_path(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = path.split('/')\n",
    "    return len(tokens) - 1\n",
    "\n",
    "def get_largest_token_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = path.split('/')\n",
    "    if tokens:\n",
    "        return max(len(token) for token in tokens)\n",
    "    return 0\n",
    "\n",
    "def get_average_token_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    tokens = [token for token in path.split('/') if token]\n",
    "    if tokens:\n",
    "        return np.mean([len(token) for token in tokens])\n",
    "    return 0\n",
    "\n",
    "def get_file_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    return len(filename)\n",
    "\n",
    "def get_dot_count_in_file(url):\n",
    "    url = ensure_scheme(url)\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    return filename.count('.')\n",
    "\n",
    "def get_delimiter_count_in_file(url):\n",
    "    path = urlparse(url).path\n",
    "    filename = path.split('/')[-1]\n",
    "    delimiters = ['.', '_', '-']\n",
    "    return sum(filename.count(delimiter) for delimiter in delimiters)\n",
    "\n",
    "def get_arguments_length(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    return len(query)\n",
    "\n",
    "def get_number_of_arguments(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    return len(parse_qs(query))\n",
    "\n",
    "def get_length_of_largest_argument_value(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    params = parse_qs(query)\n",
    "    if params:\n",
    "        return max(len(max(values, key=len)) for values in params.values())\n",
    "    return 0\n",
    "\n",
    "def get_max_delimiters_in_arguments(url):\n",
    "    url = ensure_scheme(url)\n",
    "    query = urlparse(url).query\n",
    "    params = parse_qs(query)\n",
    "    delimiters = ['&', '=', '-', '_']\n",
    "    if params:\n",
    "        return max(sum(value.count(delimiter) for delimiter in delimiters) for values in params.values() for value in values)\n",
    "    return 0\n",
    "\n",
    "\n",
    "def get_hyphen_count_in_domain(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    return domain.count('-')\n",
    "\n",
    "def contains_ip(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    try:\n",
    "        socket.inet_aton(domain)\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_domain_features(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(ensure_scheme(url)).netloc\n",
    "    tokens = domain.split('.')\n",
    "    \n",
    "    # Domain Length\n",
    "    domain_length = len(domain)\n",
    "    \n",
    "    # Count of Tokens in the Domain\n",
    "    token_count = len(tokens)\n",
    "    \n",
    "    # Length of Largest Token in the Domain\n",
    "    largest_token_length = max(len(token) for token in tokens) if tokens else 0\n",
    "    \n",
    "    # Average Domain Token Length\n",
    "    average_token_length = sum(len(token) for token in tokens) / len(tokens) if tokens else 0\n",
    "    \n",
    "    return domain_length, token_count, largest_token_length, average_token_length\n",
    "\n",
    "# New feature extraction functions\n",
    "def get_special_character_count(url):\n",
    "    special_characters = ['@', '=', '+', '*', '?', '&', '%', '$', '#', '!']\n",
    "    return sum(url.count(char) for char in special_characters)\n",
    "\n",
    "def get_entropy(url):\n",
    "    # Count the frequency of each character in the string\n",
    "    freq = Counter(url)\n",
    "    # Calculate the probabilities\n",
    "    probs = [count / len(url) for count in freq.values()]\n",
    "    # Calculate the Shannon entropy\n",
    "    entropy = -sum(p * math.log(p, 2) for p in probs if p > 0)\n",
    "    return entropy\n",
    "\n",
    "def check_url_shortened(url):\n",
    "    shortened_services = ['bit.ly', 'tinyurl.com', 'goo.gl', 'ow.ly', 't.co']\n",
    "    url = ensure_scheme(url)\n",
    "    domain = urlparse(url).netloc\n",
    "    return int(domain in shortened_services)\n",
    "\n",
    "def get_subdomain_count(url):\n",
    "    url = ensure_scheme(url)\n",
    "    domain_parts = urlparse(url).netloc.split('.')\n",
    "    # Count as subdomains any parts beyond the second-level domain and TLD\n",
    "    return max(0, len(domain_parts) - 2)\n",
    "\n",
    "def get_suspicious_tld(url):\n",
    "    suspicious_tlds = ['xyz', 'top', 'loan', 'win', 'club']\n",
    "    url = ensure_scheme(url)\n",
    "    tld = urlparse(url).netloc.split('.')[-1]\n",
    "    return int(tld in suspicious_tlds)\n",
    "\n",
    "def get_numeric_ratio(url):\n",
    "    numeric_chars = sum(c.isdigit() for c in url)\n",
    "    return numeric_chars / len(url) if len(url) > 0 else 0\n",
    "\n",
    "def get_word_count(url):\n",
    "    words = re.findall(r'\\w+', url)\n",
    "    return len(words)\n",
    "    \n",
    "\n",
    "# Apply feature extraction\n",
    "features = balanced_df['URL'].apply(lambda x: pd.Series({\n",
    "    'url_length': get_url_length(x),\n",
    "    'dot_count': get_dot_count(x),\n",
    "    'hyphen_count_domain': get_hyphen_count_in_domain(x),\n",
    "    'security_sensitive_words': contains_security_sensitive_words(x),\n",
    "    'directory_length': get_directory_length(x),\n",
    "    'sub_directory_count': get_sub_directory_count(x),\n",
    "    'token_count_path': get_token_count_in_path(x),\n",
    "    'largest_token_length': get_largest_token_length(x),\n",
    "    'average_token_length': get_average_token_length(x),\n",
    "    'file_length': get_file_length(x),\n",
    "    'contains_ip': contains_ip(x),\n",
    "    'dot_count_in_file': get_dot_count_in_file(x),\n",
    "    'delimiter_count_in_file': get_delimiter_count_in_file(x),\n",
    "    'arguments_length': get_arguments_length(x),\n",
    "    'number_of_arguments': get_number_of_arguments(x),\n",
    "    'length_of_largest_argument_value': get_length_of_largest_argument_value(x),\n",
    "    'max_delimiters_in_arguments': get_max_delimiters_in_arguments(x),\n",
    "    'special_character_count': get_special_character_count(x),\n",
    "    'entropy': get_entropy(x),\n",
    "    'url_shortened': check_url_shortened(x),\n",
    "    'subdomain_count': get_subdomain_count(x),\n",
    "    'suspicious_tld': get_suspicious_tld(x),\n",
    "    'numeric_ratio': get_numeric_ratio(x),\n",
    "    'domain_length': get_domain_features(x)[0],\n",
    "    'domain_token_count': get_domain_features(x)[1],\n",
    "    'largest_domain_token_length': get_domain_features(x)[2],\n",
    "    'average_domain_token_length': get_domain_features(x)[3],\n",
    "    'word_count': get_word_count(x)\n",
    "}))\n",
    "\n",
    "\n",
    "# Concatenate original DF with features\n",
    "balanced_df = pd.concat([balanced_df, features], axis=1)\n",
    "\n",
    "\n",
    "# Define X and y correctly\n",
    "X = balanced_df.drop(['Label', 'URL'], axis=1)  # Features\n",
    "y = balanced_df['Label']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "# Since your features are already numerical, directly use RandomForestClassifier without TfidfVectorizer\n",
    "model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "feature_selection_pipeline = Pipeline([\n",
    "    ('variance_threshold', VarianceThreshold(threshold=0)),\n",
    "])\n",
    "\n",
    "# Fit and transform the pipeline on the training data\n",
    "X_train_transformed = feature_selection_pipeline.fit_transform(X_train, y_train)\n",
    "\n",
    "# Transform the test data based on the fitted pipeline\n",
    "X_test_transformed = feature_selection_pipeline.transform(X_test)\n",
    "\n",
    "# Now, train your model on X_train_transformed and test on X_test_transformed\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
